{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Training requires a tarball python package that includes your training program based on TensorFlow. While CloudML provides several generic purpose model training, for this sample we will use a package that is specifically created to train Census sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Training\n",
    "\n",
    "First copy the package to local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-datalab/sampledata/ml/census/trainer-0.3.tar.gz...\n",
      "Downloading ...content/datalab/tmp/ml/census/trainer-0.3.tar.gz: 6.36 KiB/6.36 KiB    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://cloud-datalab/sampledata/ml/census/trainer-0.3.tar.gz /content/datalab/tmp/ml/census/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run \"%ml train\" to generate the training cell template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the required fields and run. <br>\n",
    "Datalab will simulate the CloudML service by creating master, worker, and ps processes (in cloud they are different VMs) to perform a distributed training, although all these processes run in the local container VM.<br>\n",
    "You can set replica_count to 0 to not using a certain job type, such as ps. But master is required. In this case, we only enable master.<br>\n",
    "The output of the training will be links to the processes output logs, and also refreshed every 3 seconds to show last few lines of the logs. You can use the local run to quickly validate your training program and parameters before submitting it to cloud to do large scale training.<br>\n",
    "If for any reasons the training is stuck, just click \"Reset Session\" to reset the kernel. All training processes will be cleaned up.<br><br>\n",
    "\n",
    "Note that we replaced \"scale_tier: BASIC\" to \"scale_tier: CUSTOM\" and set \"worker_count\" and \"parameter_server_count\" explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Job Running...</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/_nocachecontent/worker\" target=\"_blank\">worker log</a>&nbsp;&nbsp;<a href=\"/_nocachecontent/master\" target=\"_blank\">master log</a>&nbsp;&nbsp;<a href=\"/_nocachecontent/ps\" target=\"_blank\">ps log</a>&nbsp;&nbsp;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "master: <br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: batch/fifo_queue_enqueue = QueueEnqueue[Tcomponents=[DT_STRING, DT_STRING], _class=[\"loc:@batch/fifo_queue\"], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, ReaderRead, ReaderRead:1)]]<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], _class=[\"loc:@input_producer\"], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/Identity)]]<br/>master: Final error after 2001 steps = 48969.148<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], _class=[\"loc:@input_producer\"], timeout_ms=-1, _device=\"/job:master/replica:0/task:0/cpu:0\"](input_producer, input_producer/Identity)]]<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: batch/fifo_queue_enqueue = QueueEnqueue[Tcomponents=[DT_STRING, DT_STRING], _class=[\"loc:@batch/fifo_queue\"], timeout_ms=-1, _device=\"/job:master/replica:0/task:0/cpu:0\"](batch/fifo_queue, ReaderRead, ReaderRead:1)]]<br/>master: Done training.<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: batch/fifo_queue_enqueue = QueueEnqueue[Tcomponents=[DT_STRING, DT_STRING], _class=[\"loc:@batch/fifo_queue\"], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, ReaderRead, ReaderRead:1)]]<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], _class=[\"loc:@input_producer\"], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/Identity)]]<br/>master: <br/>worker: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>worker: \t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], _class=[\"loc:@input_producer\"], timeout_ms=-1, _device=\"/job:worker/replica:0/task:0/cpu:0\"](input_producer, input_producer/Identity)]]<br/>worker: Done training.<br/>worker: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Job Finished.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%ml train\n",
    "package_uris: /content/datalab/tmp/ml/census/trainer-0.3.tar.gz\n",
    "python_module: trainer.task\n",
    "scale_tier: CUSTOM\n",
    "worker_count: 1\n",
    "parameter_server_count: 1\n",
    "args:\n",
    "  train_data_paths:\n",
    "    - /content/datalab/tmp/ml/census/preprocessed/features_train\n",
    "  eval_data_paths:\n",
    "    - /content/datalab/tmp/ml/census/preprocessed/features_eval\n",
    "  metadata_path: /content/datalab/tmp/ml/census/preprocessed/metadata.yaml\n",
    "  output_path: /content/datalab/tmp/ml/census/model\n",
    "  hidden1: 100\n",
    "  hidden2: 60\n",
    "  hidden3: 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the training output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval  logdir  model  summaries\r\n"
     ]
    }
   ],
   "source": [
    "!ls /content/datalab/tmp/ml/census/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start TensorBoard to view training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 19769. Click <a href=\"/_proxy/53955/\" target=\"_blank\">here</a> to access it.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorboard start --logdir /content/datalab/tmp/ml/census/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shut down the tensorboard serverwhen you are done with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%tensorboard stop --pid 19769"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train another model with larger hidden layer sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Job Running...</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/_nocachecontent/worker\" target=\"_blank\">worker log</a>&nbsp;&nbsp;<a href=\"/_nocachecontent/master\" target=\"_blank\">master log</a>&nbsp;&nbsp;<a href=\"/_nocachecontent/ps\" target=\"_blank\">ps log</a>&nbsp;&nbsp;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "master: Step 2000: loss = 57326.97 (0.038 sec)<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: batch/fifo_queue_enqueue = QueueEnqueue[Tcomponents=[DT_STRING, DT_STRING], _class=[\"loc:@batch/fifo_queue\"], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, ReaderRead, ReaderRead:1)]]<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], _class=[\"loc:@input_producer\"], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/Identity)]]<br/>master: Final error after 2000 steps = 49385.258<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], _class=[\"loc:@input_producer\"], timeout_ms=-1, _device=\"/job:master/replica:0/task:0/cpu:0\"](input_producer, input_producer/Identity)]]<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: batch/fifo_queue_enqueue = QueueEnqueue[Tcomponents=[DT_STRING, DT_STRING], _class=[\"loc:@batch/fifo_queue\"], timeout_ms=-1, _device=\"/job:master/replica:0/task:0/cpu:0\"](batch/fifo_queue, ReaderRead, ReaderRead:1)]]<br/>master: Done training.<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], _class=[\"loc:@input_producer\"], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer, input_producer/Identity)]]<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: batch/fifo_queue_enqueue = QueueEnqueue[Tcomponents=[DT_STRING, DT_STRING], _class=[\"loc:@batch/fifo_queue\"], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](batch/fifo_queue, ReaderRead, ReaderRead:1)]]<br/>master: <br/>worker: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>worker: \t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], _class=[\"loc:@input_producer\"], timeout_ms=-1, _device=\"/job:worker/replica:0/task:0/cpu:0\"](input_producer, input_producer/Identity)]]<br/>worker: Done training.<br/>worker: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Job Finished.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%ml train\n",
    "package_uris: /content/datalab/tmp/ml/census/trainer-0.3.tar.gz\n",
    "python_module: trainer.task\n",
    "scale_tier: CUSTOM\n",
    "worker_count: 1\n",
    "parameter_server_count: 1\n",
    "args:\n",
    "  train_data_paths:\n",
    "    - /content/datalab/tmp/ml/census/preprocessed/features_train\n",
    "  eval_data_paths:\n",
    "    - /content/datalab/tmp/ml/census/preprocessed/features_eval\n",
    "  metadata_path: /content/datalab/tmp/ml/census/preprocessed/metadata.yaml\n",
    "  output_path: /content/datalab/tmp/ml/census/largermodel\n",
    "  hidden1: 200\n",
    "  hidden2: 100\n",
    "  hidden3: 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Training\n",
    "\n",
    "Cloud training is similar but with \"--cloud\" flag, and use all GCS paths instead of local paths. <br>\n",
    "You also need to make sure you have a project whitelisted for CloudML, and use \"%projects set project-id\" to set it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables that will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "bucket = 'gs://' + datalab_project_id() + '-sampledata'\n",
    "package_path = os.path.join(bucket, 'census', 'model', 'trainer-0.3.tar.gz')\n",
    "train_data_path = os.path.join(bucket, 'census', 'preprocessed', 'features_train')\n",
    "eval_data_path = os.path.join(bucket, 'census', 'preprocessed', 'features_eval')\n",
    "metadata_path = os.path.join(bucket, 'census', 'preprocessed', 'metadata.yaml')\n",
    "output_path = os.path.join(bucket, 'census', 'trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-datalab/sampledata/ml/census/trainer-0.3.tar.gz [Content-Type=application/gzip]...\n",
      "Copying     ...mated-sampledata/census/model/trainer-0.3.tar.gz: 6.36 KiB/6.36 KiB    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://cloud-datalab/sampledata/ml/census/trainer-0.3.tar.gz $package_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training using the Cloud DataFlow output from the \"2. Preprocessing\" notebook. We choose a set of hidden layer sizes, and later we will show how to sweep hyperparameter values using CloudML service using hyperparameter tuning feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Job \"trainer_task_160901_200438\" was submitted successfully.<br/>Run \"%ml jobs --name trainer_task_160901_200438\" to view the status of the job.</p><p>Click <a href=\"https://console.developers.google.com/logs/viewer?project=cloud-ml-test-automated&resource=ml.googleapis.com%2Fjob_id%2Ftrainer_task_160901_200438\" target=\"_blank\">here</a> to view cloud log. <br/>Start TensorBoard by running \"%tensorboard start --logdir=&lt;YourLogDir&gt;\".</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ml train --cloud\n",
    "package_uris: $package_path\n",
    "python_module: trainer.task\n",
    "scale_tier: BASIC\n",
    "region: us-west1\n",
    "args:\n",
    "  train_data_paths:\n",
    "    - $train_data_path\n",
    "  eval_data_paths:\n",
    "    - $eval_data_path\n",
    "  metadata_path: $metadata_path\n",
    "  output_path: $output_path\n",
    "  hidden1: 200\n",
    "  hidden2: 100\n",
    "  hidden3: 50    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the job status as described in the output. You can also run \"%ml jobs --filter state!=SUCCEEDED\" to see all active ML jobs in that project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>createTime: '2016-09-01T20:04:39.000Z'\n",
       "jobId: trainer_task_160901_200438\n",
       "startTime: '2016-09-01T20:07:14.000Z'\n",
       "state: RUNNING\n",
       "trainingInput:\n",
       "  args: [--hidden3, '50', --hidden2, '100', --hidden1, '200', --output_path, 'gs://cloud-ml-test-automated-sampledata/census/trained',\n",
       "    --train_data_paths, 'gs://cloud-ml-test-automated-sampledata/census/preprocessed/features_train',\n",
       "    --metadata_path, 'gs://cloud-ml-test-automated-sampledata/census/preprocessed/metadata.yaml',\n",
       "    --eval_data_paths, 'gs://cloud-ml-test-automated-sampledata/census/preprocessed/features_eval']\n",
       "  packageUris: ['gs://cloud-ml-test-automated-sampledata/census/model/trainer-0.3.tar.gz']\n",
       "  pythonModule: trainer.task\n",
       "  region: us-west1\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ml jobs --name trainer_task_160901_200438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-test-automated-sampledata/census/trained/eval/\r\n",
      "gs://cloud-ml-test-automated-sampledata/census/trained/logdir/\r\n",
      "gs://cloud-ml-test-automated-sampledata/census/trained/model/\r\n",
      "gs://cloud-ml-test-automated-sampledata/census/trained/summaries/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://cloud-ml-test-automated-sampledata/census/trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
