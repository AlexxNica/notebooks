{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Training requires a tarball python package that includes your training program based on TensorFlow. While CloudML provides several generic purpose model training, for this sample we will use a package that is used to train Iris sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Package\n",
    "\n",
    "You can use existing tarball package (locally or in GCS), or use your own tarball package. You can define a python module use \"%%ml module\". In the following two cells, we will define two python modules: \"iris\" and \"task\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml module --name iris\n",
    "\n",
    "import google.cloud.ml.features as features\n",
    "import json\n",
    "import math\n",
    "import tensorflow as tf\n",
    "\n",
    "def read_examples(input_files, batch_size, shuffle, num_epochs=None):\n",
    "  # The minimum number of instances in a queue from which examples are drawn\n",
    "  # randomly. The larger this number, the more randomness at the expense of\n",
    "  # higher memory requirements.\n",
    "  MIN_AFTER_DEQUEUE = 100\n",
    "  # When batching data, the queue's capacity will be larger than the batch_size\n",
    "  # by some factor. The recommended formula is (num_threads + a small safety\n",
    "  # margin). For now, we use a single thread for reading, so this can be small.\n",
    "  QUEUE_SIZE_MULTIPLIER = 3\n",
    "\n",
    "  # Convert num_epochs == 0 -> num_epochs is None, if necessary\n",
    "  num_epochs = num_epochs or None\n",
    "\n",
    "  # Build a queue of the filenames to be read.\n",
    "  filename_queue = tf.train.string_input_producer(input_files, num_epochs,\n",
    "                                                  shuffle)\n",
    "  options = tf.python_io.TFRecordOptions(\n",
    "      compression_type=tf.python_io.TFRecordCompressionType.ZLIB)\n",
    "  example_id, encoded_example = tf.TFRecordReader(options=options).read(\n",
    "      filename_queue)\n",
    "\n",
    "  if shuffle:\n",
    "    capacity = MIN_AFTER_DEQUEUE + QUEUE_SIZE_MULTIPLIER * batch_size\n",
    "    return tf.train.shuffle_batch([example_id, encoded_example], batch_size,\n",
    "                                  capacity, MIN_AFTER_DEQUEUE)\n",
    "  else:\n",
    "    capacity = QUEUE_SIZE_MULTIPLIER * batch_size\n",
    "    return tf.train.batch([example_id, encoded_example],\n",
    "                          batch_size,\n",
    "                          capacity=capacity)\n",
    "\n",
    "def create_inputs(metadata, input_data=None):\n",
    "  with tf.name_scope('inputs'):\n",
    "    if input_data is None:\n",
    "      input_data = tf.placeholder(tf.string, name='input', shape=(None,))\n",
    "    parsed = features.FeatureMetadata.parse_features(metadata, input_data)\n",
    "    return (input_data, parsed['measurements'], tf.squeeze(parsed['species']),\n",
    "            tf.identity(parsed['key']))\n",
    "\n",
    "def inference(measurements, metadata, hidden_layer_size):\n",
    "  input_size = metadata.features['measurements']['size']\n",
    "  output_size = hidden_layer_size\n",
    "\n",
    "  with tf.name_scope('hidden_layer'):\n",
    "    initial_weights = tf.truncated_normal([ input_size, output_size ],\n",
    "                                          stddev = 1.0 / math.sqrt(input_size))\n",
    "    weights = tf.Variable(initial_weights, name = 'weights')\n",
    "\n",
    "    initial_biases = tf.zeros([ output_size ])\n",
    "    biases = tf.Variable(initial_biases, name = 'biases')\n",
    "\n",
    "    xw = tf.matmul(measurements, weights)\n",
    "\n",
    "    xwb = tf.nn.bias_add(xw, biases)\n",
    "    hidden_layer = tf.nn.relu(xwb)\n",
    "\n",
    "  input_size = hidden_layer_size\n",
    "  output_size = metadata.labels\n",
    "\n",
    "  with tf.name_scope('logits_layer'):\n",
    "    initial_weights = tf.truncated_normal([ input_size, output_size ],\n",
    "                                          stddev = 1.0 / math.sqrt(input_size))\n",
    "    weights = tf.Variable(initial_weights, name = 'weights')\n",
    "\n",
    "    initial_biases = tf.zeros([ output_size ])\n",
    "    biases = tf.Variable(initial_biases, name = 'biases')\n",
    "\n",
    "    return tf.nn.bias_add(tf.matmul(hidden_layer, weights), biases, name='logits')\n",
    "\n",
    "def loss(logits, labels):\n",
    "  labels = tf.to_int64(labels)\n",
    "  cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "      logits, labels, name='xentropy')\n",
    "  loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "  return loss\n",
    "\n",
    "def create_outputs(logits):\n",
    "  with tf.name_scope('outputs'):\n",
    "    scores = tf.nn.softmax(logits, name = 'scores')\n",
    "    predictions = tf.arg_max(logits, 1, name = 'prediction')\n",
    "    return scores, predictions\n",
    "\n",
    "def training(loss, learning_rate):\n",
    "  with tf.name_scope('train'):\n",
    "    tf.scalar_summary(loss.op.name, loss)\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(loss, global_step)\n",
    "    return train_op, global_step\n",
    "\n",
    "def evaluation(logits, labels):\n",
    "  # For a classifier model, we can use the in_top_k Op.\n",
    "  # It returns a bool tensor with shape [batch_size] that is true for\n",
    "  # the examples where the label is in the top k (here k=1)\n",
    "  # of all logits for that example.\n",
    "  correct = tf.nn.in_top_k(logits, labels, 1)\n",
    "  # Return the number of true entries.\n",
    "  return tf.reduce_sum(tf.cast(correct, tf.int32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define \"task\" module. \"--main\" indicates this is the entry point of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml module --name task --main\n",
    "\n",
    "import argparse\n",
    "import itertools\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import iris\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.metrics.python.ops import metric_ops\n",
    "\n",
    "import google.cloud.ml.features as features\n",
    "import google.cloud.ml.util as cloudml_util\n",
    "\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def main():\n",
    "  config = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
    "  cluster = config.get('cluster', None)\n",
    "  task = config.get('task', None)\n",
    "  job = config.get('job', None)\n",
    "  trial_id = task.get('trial', '')\n",
    "  \n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.add_argument(\"--train_data_paths\", type=str, action='append')\n",
    "  parser.add_argument(\"--eval_data_paths\", type=str, action='append')\n",
    "  parser.add_argument(\"--metadata_path\", type=str)\n",
    "  parser.add_argument(\"--output_path\", type=str)\n",
    "  parser.add_argument(\"--learning_rate\", type=float, default=0.01)\n",
    "  parser.add_argument(\"--hidden\", type=int, default=10)\n",
    "  parser.add_argument(\"--max_steps\", type=int, default=2000)\n",
    "  args = parser.parse_args()\n",
    "  dispatch(args, cluster, task, job, trial_id)\n",
    "\n",
    "EXPORT_SUBDIRECTORY = 'model'\n",
    "BATCH_SIZE = 16\n",
    "EVAL_SET_SIZE = 30\n",
    "EVAL_INTERVAL_SECS = 10\n",
    "\n",
    "def write_label_file(dir, args, trial_id):\n",
    "  cloudml_util._file.create_directory(dir)\n",
    "  label_file = os.path.join(dir, 'label')\n",
    "  data = 'trial:' + trial_id + '/' if trial_id else ''\n",
    "  data += 'learning_rate:%0.5f/hidden:%d' % (args.learning_rate, args.hidden)\n",
    "  with tempfile.NamedTemporaryFile() as temp:\n",
    "    temp.write('data')\n",
    "    temp.flush()\n",
    "    subprocess.check_call(['gsutil', 'cp', temp.name, label_file])\n",
    "\n",
    "\n",
    "def print_to_console(msg):\n",
    "  print msg\n",
    "  sys.stdout.flush()\n",
    "\n",
    "\n",
    "def start_server(cluster, task):\n",
    "  # Create and start a server.\n",
    "  return tf.train.Server(cluster,\n",
    "                         protocol=\"grpc\",\n",
    "                         job_name=task['type'],\n",
    "                         task_index=task['index'])\n",
    "\n",
    "\n",
    "def dispatch(args, cluster, task, job, trial_id):\n",
    "  if not cluster:\n",
    "    # Run locally.\n",
    "    run_training(args, target=\"\", is_chief=True, device_fn=\"\", trial_id=trial_id)\n",
    "    return\n",
    "\n",
    "  if task['type'] == \"ps\":\n",
    "    server = start_server(cluster, task)\n",
    "    server.join()\n",
    "  elif task['type'] == \"worker\":\n",
    "    server = start_server(cluster, task)\n",
    "    is_chief = False\n",
    "    device_fn = tf.train.replica_device_setter(\n",
    "        ps_device=\"/job:ps\",\n",
    "        worker_device=\"/job:worker/task:%d\" % task['index'],\n",
    "        cluster=cluster)\n",
    "    run_training(args, server.target, is_chief, device_fn, task['index'], trial_id)\n",
    "  elif task['type'] == \"master\":\n",
    "    server = start_server(cluster, task)\n",
    "    is_chief = (task['index'] == 0)\n",
    "    device_fn = tf.train.replica_device_setter(\n",
    "        ps_device=\"/job:ps\",\n",
    "        worker_device=\"/job:master/task:%d\" % task['index'],\n",
    "        cluster=cluster)\n",
    "    run_training(args, server.target, is_chief, device_fn, task['index'], trial_id)\n",
    "  else:\n",
    "    raise ValueError(\"invalid job_type %s\" % task['type'])\n",
    "\n",
    "\n",
    "def run_training(args, target, is_chief, device_fn, task_index, trial_id):\n",
    "\n",
    "  output_path = os.path.join(args.output_path, trial_id)\n",
    "  # Get the sets of examples and labels for training, validation, and\n",
    "  # test on Iris.\n",
    "  training_data = args.train_data_paths\n",
    "\n",
    "  if is_chief:\n",
    "    # A generator over accuracies. Each call to next(accuracies) forces an\n",
    "    # evaluation of the model.\n",
    "    accuracies = evaluate(args, trial_id)\n",
    "\n",
    "  # Tell TensorFlow that the model will be built into the default Graph.\n",
    "  with tf.Graph().as_default() as graph:\n",
    "    # Assigns ops to the local worker by default.\n",
    "    with tf.device(device_fn):\n",
    "\n",
    "      metadata = features.FeatureMetadata.get_metadata(args.metadata_path)\n",
    "\n",
    "      _, train_examples = iris.read_examples(\n",
    "          training_data, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "      # Generate placeholders for the examples.\n",
    "      placeholder, measurements, labels, _ = (\n",
    "          iris.create_inputs(metadata, input_data=train_examples))\n",
    "\n",
    "      # Build a Graph that computes predictions from the inference model.\n",
    "      logits = iris.inference(measurements, metadata, args.hidden)\n",
    "\n",
    "      # Add to the Graph the Ops for loss calculation.\n",
    "      loss = iris.loss(logits, labels)\n",
    "\n",
    "      # Add to the Graph the Ops that calculate and apply gradients.\n",
    "      train_op, global_step = iris.training(loss, args.learning_rate)\n",
    "\n",
    "      # Add the Op to compare the logits to the labels during evaluation.\n",
    "      eval_correct = iris.evaluation(logits, labels)\n",
    "\n",
    "      # Build the summary operation based on the TF collection of Summaries.\n",
    "      summary_op = tf.merge_all_summaries()\n",
    "\n",
    "      # Add the variable initializer Op.\n",
    "      init_op = tf.initialize_all_variables()\n",
    "\n",
    "      # Create a saver for writing training checkpoints.\n",
    "      saver = tf.train.Saver()\n",
    "\n",
    "      # Instantiate a SummaryWriter to output summaries and the Graph.\n",
    "      summary_writer = tf.train.SummaryWriter(os.path.join(\n",
    "          output_path, 'summaries'), graph)\n",
    "\n",
    "      if is_chief:\n",
    "        write_label_file(os.path.join(output_path, 'summaries'), args, trial_id)\n",
    "\n",
    "      # Create a \"supervisor\", which oversees the training process.\n",
    "      sv = tf.train.Supervisor(is_chief=is_chief,\n",
    "                               logdir=os.path.join(output_path, 'logdir'),\n",
    "                               init_op=init_op,\n",
    "                               saver=saver,\n",
    "                               summary_op=None,\n",
    "                               global_step=global_step,\n",
    "                               save_model_secs=60)\n",
    "\n",
    "    print_to_console(\"Starting the loop.\")\n",
    "    device_filters = [\"/job:ps\", \"/job:worker/task:%d\" % (task_index)]\n",
    "    config = tf.ConfigProto(device_filters=device_filters)\n",
    "\n",
    "    should_retry = True\n",
    "    while should_retry:\n",
    "      try:\n",
    "        should_retry = False\n",
    "        with sv.managed_session(target, config=config) as sess:\n",
    "          start_time = time.time()\n",
    "          last_save = start_time\n",
    "\n",
    "          # Loop until the supervisor shuts down or 1000 steps have completed.\n",
    "          step = 0\n",
    "          while not sv.should_stop() and step < args.max_steps:\n",
    "            start_time = time.time()\n",
    "\n",
    "            _, step, loss_value = sess.run([train_op, global_step, loss])\n",
    "\n",
    "            duration = time.time() - start_time\n",
    "            if is_chief and time.time() - last_save > EVAL_INTERVAL_SECS:\n",
    "              last_save = time.time()\n",
    "              saver.save(sess, sv.save_path, global_step)\n",
    "              accuracy = next(accuracies)\n",
    "              logging.info(\"Eval, step %d: accuracy = %0.3f\", step, accuracy)\n",
    "              print_to_console(\"Eval, step %d: accuracy = %0.3f\" % (step, accuracy))\n",
    "\n",
    "            # Write the summaries and log an overview fairly often.\n",
    "            if step % 100 == 0 and is_chief:\n",
    "              # Log status.\n",
    "              logging.info(\"Step %d: loss = %.2f (%.3f sec)\",\n",
    "                           step, loss_value, duration)\n",
    "              print_to_console(\"Step %d: loss = %.2f (%.3f sec)\" % (step, loss_value, duration))\n",
    "\n",
    "              # Update the events file.\n",
    "              summary_str = sess.run(summary_op)\n",
    "              summary_writer.add_summary(summary_str, step)\n",
    "              summary_writer.flush()\n",
    "\n",
    "          if is_chief:\n",
    "            # Force a save at the end of our loop.\n",
    "            sv.saver.save(sess, sv.save_path, global_step=global_step,\n",
    "                          write_meta_graph=False)\n",
    "            accuracy_value = next(accuracies)\n",
    "            logging.info(\"Final accuracy after %d steps = %0.3f\", step, accuracy_value)\n",
    "            print_to_console(\"Final accuracy after %d steps = %0.3f\" % (step, accuracy_value))\n",
    "\n",
    "            # Save the model for inference\n",
    "            export_model(args, sess, sv.saver, trial_id)\n",
    "      except tf.errors.AbortedError:\n",
    "        should_retry = True\n",
    "\n",
    "    # Ask for all the services to stop.\n",
    "    sv.stop()\n",
    "    print_to_console(\"Done training.\")\n",
    "\n",
    "\n",
    "def export_model(args, sess, training_saver, trial_id):\n",
    "  output_path = os.path.join(args.output_path, trial_id)\n",
    "  with tf.Graph().as_default() as inference_graph:\n",
    "    metadata = features.FeatureMetadata.get_metadata(args.metadata_path)\n",
    "    placeholder, measurements, _, keys = iris.create_inputs(metadata)\n",
    "    logits = iris.inference(measurements, metadata, args.hidden)\n",
    "    scores, predictions = iris.create_outputs(logits)\n",
    "\n",
    "    inference_saver = tf.train.Saver()\n",
    "\n",
    "    # Mark the inputs and the outputs\n",
    "    tf.add_to_collection(\"inputs\",\n",
    "                         json.dumps({\"examples\": placeholder.name}))\n",
    "    tf.add_to_collection(\"outputs\",\n",
    "                         json.dumps({\"score\": scores.name,\n",
    "                                     \"predictions\": predictions.name}))\n",
    "    tf.add_to_collection(\"keys\", json.dumps({\"key\": keys.name}))\n",
    "\n",
    "    model_dir = os.path.join(output_path, EXPORT_SUBDIRECTORY)\n",
    "\n",
    "    # Save a copy of the metadata file used for this model with the exported\n",
    "    # model, so that online and batch prediction can use it.\n",
    "    subprocess.check_call(['gsutil', 'cp', args.metadata_path,\n",
    "                           os.path.join(model_dir, \"metadata.yaml\")])\n",
    "\n",
    "    # We need to save the variables from the training session, but we need\n",
    "    # to serialize the serving graph.\n",
    "\n",
    "    # Serialize the graph (MetaGraphDef)\n",
    "    inference_saver.export_meta_graph(\n",
    "        filename=os.path.join(model_dir, \"export.meta\"))\n",
    "\n",
    "    # Save the variables. Don't write the MetaGraphDef, because that is\n",
    "    # actually the training graph.\n",
    "    training_saver.save(sess,\n",
    "                        os.path.join(model_dir, \"export\"),\n",
    "                        write_meta_graph=False)\n",
    "\n",
    "\n",
    "def evaluate(args, trial_id):\n",
    "  \"\"\"Run one round of evaluation, yielding accuracy.\"\"\"\n",
    "  output_path = os.path.join(args.output_path, trial_id)\n",
    "  eval_data = args.eval_data_paths\n",
    "\n",
    "  with tf.Graph().as_default() as g:\n",
    "    metadata = features.FeatureMetadata.get_metadata(args.metadata_path)\n",
    "\n",
    "    _, examples = iris.read_examples(\n",
    "        eval_data, BATCH_SIZE,\n",
    "        shuffle=False, num_epochs=1)\n",
    "\n",
    "    # Generate placeholders for the examples.\n",
    "    placeholder, measurements, labels, _ = (\n",
    "        iris.create_inputs(metadata, input_data=examples))\n",
    "\n",
    "    # Build a Graph that computes predictions from the inference model.\n",
    "    logits = iris.inference(measurements, metadata, args.hidden)\n",
    "\n",
    "    # Add to the Graph the Ops for loss calculation.\n",
    "    loss = iris.loss(logits, labels)\n",
    "\n",
    "    # Add the Op to compute accuracy.\n",
    "    accuracy_op, eval_op = metric_ops.streaming_accuracy(\n",
    "        tf.argmax(logits, 1), labels)\n",
    "\n",
    "    # The global step is useful for summaries.\n",
    "    with tf.name_scope('train'):\n",
    "      global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "    summary = tf.scalar_summary(\"accuracy\", accuracy_op)\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "  num_eval_batches = float(EVAL_SET_SIZE) / BATCH_SIZE\n",
    "  summary_writer = tf.train.SummaryWriter(os.path.join(\n",
    "      output_path, 'eval'))\n",
    "\n",
    "  write_label_file(os.path.join(output_path, 'eval'), args, trial_id)\n",
    "\n",
    "  sv = tf.train.Supervisor(graph=g,\n",
    "                           logdir=os.path.join(output_path, 'eval'),\n",
    "                           summary_op=summary,\n",
    "                           summary_writer=summary_writer,\n",
    "                           global_step=None,\n",
    "                           saver=saver)\n",
    "  step = 0\n",
    "  while step < args.max_steps:\n",
    "    last_checkpoint = tf.train.latest_checkpoint(os.path.join(\n",
    "        output_path, 'logdir'))\n",
    "    with sv.managed_session(master=\"\",\n",
    "                            start_standard_services=False) as session:\n",
    "      sv.start_queue_runners(session)\n",
    "      sv.saver.restore(session, last_checkpoint)\n",
    "      accuracy = tf_evaluation(session,\n",
    "                               num_evals=num_eval_batches,\n",
    "                               eval_op=eval_op,\n",
    "                               final_op=accuracy_op,\n",
    "                               summary_op=summary,\n",
    "                               summary_writer=summary_writer,\n",
    "                               global_step=global_step)\n",
    "\n",
    "      step = tf.train.global_step(session, global_step)\n",
    "      yield accuracy\n",
    "\n",
    "\n",
    "def tf_evaluation(sess,\n",
    "                  num_evals=1,\n",
    "                  init_op=None,\n",
    "                  init_op_feed_dict=None,\n",
    "                  eval_op=None,\n",
    "                  eval_op_feed_dict=None,\n",
    "                  final_op=None,\n",
    "                  final_op_feed_dict=None,\n",
    "                  summary_op=None,\n",
    "                  summary_op_feed_dict=None,\n",
    "                  summary_writer=None,\n",
    "                  global_step=None):\n",
    "  if init_op is not None:\n",
    "    sess.run(init_op, init_op_feed_dict)\n",
    "\n",
    "  if eval_op is not None:\n",
    "    for i in range(int(num_evals)):\n",
    "      sess.run(eval_op, eval_op_feed_dict)\n",
    "\n",
    "  if final_op is not None:\n",
    "    final_op_value = sess.run(final_op, final_op_feed_dict)\n",
    "  else:\n",
    "    final_op_value = None\n",
    "\n",
    "  if summary_op is not None:\n",
    "    if global_step is None:\n",
    "      raise ValueError(\"must specify global step\")\n",
    "\n",
    "    global_step = tf.train.global_step(sess, global_step)\n",
    "    summary = sess.run(summary_op, summary_op_feed_dict)\n",
    "    hptuning_summary = tf.Summary(value=[\n",
    "      tf.Summary.Value(tag='training/hptuning/metric', simple_value=float(final_op_value))\n",
    "    ])\n",
    "    summary_writer.add_summary(summary, global_step)\n",
    "    summary_writer.add_summary(hptuning_summary, global_step)\n",
    "    summary_writer.flush()\n",
    "  \n",
    "  return final_op_value\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run \"%ml train\" to generate the training cell template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%ml train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the required fields and run. <br><br>\n",
    "Datalab will simulate the CloudML service by creating master, worker, and ps processes (in cloud they are different VMs) to perform a distributed training, although all these processes run in the local container VM.<br>\n",
    "You can set replica_count to 0 to not using a certain job type, such as ps. But master is required.<br>\n",
    "The output of the training will be links to the processes output logs, and also refreshed every 3 seconds to show last few lines of the logs. You can use the local run to quickly validate your training program and parameters before submitting it to cloud to do large scale training.<br>\n",
    "If for any reasons the training is stuck, just click \"Reset Session\" to reset the kernel. All training processes will be cleaned up. <br>\n",
    "\n",
    "There are two ways you could specify a trainer program: you can specify \"package_uris\" and \"python_module\" in the input cell for existing tarball package. Or, if these are absent, it will look for all \"%%ml module\" cells and create a temp tarball package to run. <br>\n",
    "\n",
    "Since we already defined our training modules, let's run the training program without explicitly specifying package. Datalab will create a temp package and will run the entrypoint module specified by \"--main\" flag. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Job Running...</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/_nocachecontent/worker\" target=\"_blank\">worker log</a>&nbsp;&nbsp;<a href=\"/_nocachecontent/master\" target=\"_blank\">master log</a>&nbsp;&nbsp;<a href=\"/_nocachecontent/ps\" target=\"_blank\">ps log</a>&nbsp;&nbsp;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "master: Operation completed over 1 objects/4.0 B.                                        <br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Reached limit of 1<br/>master: \t [[Node: input_producer/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[\"loc:@input_producer/limit_epochs/epochs\"], limit=1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer/limit_epochs/epochs)]]<br/>master: Final accuracy after 2000 steps = 0.938<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] FIFOQueue '_3_input_producer' is closed and has insufficient elements (requested 1, current size 0)<br/>master: \t [[Node: ReaderRead = ReaderRead[_class=[\"loc:@TFRecordReader\", \"loc:@input_producer\"], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](TFRecordReader, input_producer)]]<br/>master: Copying file:///content/datalab/tmp/ml/iris/preprocessed/metadata.yaml...<br/>master: / [0 files][    0.0 B/  1.5 KiB]                                                <br/>master: / [1 files][  1.5 KiB/  1.5 KiB]                                                <br/>master: Operation completed over 1 objects/1.5 KiB.                                      <br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: batch/fifo_queue_enqueue = QueueEnqueue[Tcomponents=[DT_STRING, DT_STRING], _class=[\"loc:@batch/fifo_queue\"], timeout_ms=-1, _device=\"/job:master/replica:0/task:0/cpu:0\"](batch/fifo_queue, ReaderRead, ReaderRead:1)]]<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], _class=[\"loc:@input_producer\"], timeout_ms=-1, _device=\"/job:master/replica:0/task:0/cpu:0\"](input_producer, input_producer/Identity)]]<br/>master: Done training.<br/>master: <br/>worker: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>worker: \t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], _class=[\"loc:@input_producer\"], timeout_ms=-1, _device=\"/job:worker/replica:0/task:0/cpu:0\"](input_producer, input_producer/Identity)]]<br/>worker: Done training.<br/>worker: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Job Finished.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%ml train\n",
    "worker_count: 1\n",
    "parameter_server_count: 1\n",
    "args:\n",
    "  train_data_paths:\n",
    "    - /content/datalab/tmp/ml/iris/preprocessed/features_train\n",
    "  eval_data_paths:\n",
    "    - /content/datalab/tmp/ml/iris/preprocessed/features_eval\n",
    "  metadata_path: /content/datalab/tmp/ml/iris/preprocessed/metadata.yaml\n",
    "  output_path: /content/datalab/tmp/ml/iris/model\n",
    "  max_steps: 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that after training is completed, you can increment \"max_steps\" and run it again. Training will resume from previous checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output of the training. \"model\" dir includes the model file (last checkpoint, graph metadata, etc). \"summaries\" dir includes summary events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval  logdir  model  summaries\r\n"
     ]
    }
   ],
   "source": [
    "!ls /content/datalab/tmp/ml/iris/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start TensorBoard to view training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 142438. Click <a href=\"/_proxy/47484/\" target=\"_blank\">here</a> to access it.</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tensorboard start --logdir /content/datalab/tmp/ml/iris/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shut down the tensorboard server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%tensorboard stop --pid 142438"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train another one for fun (with learning_rate equal to 0.001). learning_rate is an arg defined in training program in the package and default value is 0.01.\n",
    "\n",
    "Instead of running the modules defined by \"%%ml modules\" directly, we will package the modules first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package created at /content/datalab/tmp/ml/iris/trainer-0.1.tar.gz.\n"
     ]
    }
   ],
   "source": [
    "%%ml package --out /content/datalab/tmp/ml/iris/ --name trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the package explicitly by package_uris. Since we don't specify 'parameter_server_count' or 'worker_count', we will use one master only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Job Running...</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"/_nocachecontent/master\" target=\"_blank\">master log</a>&nbsp;&nbsp;"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "master: Step 2600: loss = 1.02 (0.013 sec)<br/>master: <br/>master: Step 2700: loss = 1.00 (0.013 sec)<br/>master: Step 2800: loss = 0.99 (0.013 sec)<br/>master: <br/>master: Step 2900: loss = 1.01 (0.013 sec)<br/>master: Step 3000: loss = 1.03 (0.013 sec)<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Reached limit of 1<br/>master: \t [[Node: input_producer/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[\"loc:@input_producer/limit_epochs/epochs\"], limit=1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer/limit_epochs/epochs)]]<br/>master: Final accuracy after 3000 steps = 0.875<br/>master: Copying file:///content/datalab/tmp/ml/iris/preprocessed/metadata.yaml...<br/>master: / [0 files][    0.0 B/  1.5 KiB]                                                <br/>master: / [1 files][  1.5 KiB/  1.5 KiB]                                                <br/>master: Operation completed over 1 objects/1.5 KiB.                                      <br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: batch/fifo_queue_enqueue = QueueEnqueue[Tcomponents=[DT_STRING, DT_STRING], _class=[\"loc:@batch/fifo_queue\"], timeout_ms=-1, _device=\"/job:master/replica:0/task:0/cpu:0\"](batch/fifo_queue, ReaderRead, ReaderRead:1)]]<br/>master: E tensorflow/core/client/tensor_c_api.cc:485] Enqueue operation was cancelled<br/>master: \t [[Node: input_producer/input_producer_EnqueueMany = QueueEnqueueMany[Tcomponents=[DT_STRING], _class=[\"loc:@input_producer\"], timeout_ms=-1, _device=\"/job:master/replica:0/task:0/cpu:0\"](input_producer, input_producer/Identity)]]<br/>master: Done training.<br/>master: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p>Job Finished.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%ml train\n",
    "package_uris: /content/datalab/tmp/ml/iris/trainer-0.1.tar.gz\n",
    "python_module: trainer.task\n",
    "args:\n",
    "  train_data_paths:\n",
    "    - /content/datalab/tmp/ml/iris/preprocessed/features_train\n",
    "  eval_data_paths:\n",
    "    - /content/datalab/tmp/ml/iris/preprocessed/features_eval\n",
    "  metadata_path: /content/datalab/tmp/ml/iris/preprocessed/metadata.yaml\n",
    "  output_path: /content/datalab/tmp/ml/iris/model_lr\n",
    "  max_steps: 3000\n",
    "  learning_rate: 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Training\n",
    "\n",
    "Cloud training is similar but with \"--cloud\" flag, and use all GCS paths instead of local paths. <br>\n",
    "We will use the preprocessed files created by cloud preprocessing in previous \"Preprocess\" notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables that will be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "bucket = 'gs://' + datalab_project_id() + '-sampledata'\n",
    "package_path = os.path.join(bucket, 'iris', 'model', 'trainer-0.1.tar.gz')\n",
    "train_data_path = os.path.join(bucket, 'iris', 'preprocessed', 'features_train')\n",
    "eval_data_path = os.path.join(bucket, 'iris', 'preprocessed', 'features_eval')\n",
    "metadata_path = os.path.join(bucket, 'iris', 'preprocessed', 'metadata.yaml')\n",
    "output_path = os.path.join(bucket, 'iris', 'trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy trainer package to a GCS path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///content/datalab/tmp/ml/iris/trainer-0.1.tar.gz [Content-Type=application/x-tar]...\n",
      "/ [1 files][  5.6 KiB/  5.6 KiB]                                                \n",
      "Operation completed over 1 objects/5.6 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp /content/datalab/tmp/ml/iris/trainer-0.1.tar.gz $package_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cloud training, there are extra required fields that need to be filled. It needs explicit trainer package so 'package_uris' and 'python_module' are required. 'scale_tier' and 'region' are also required to indicate training scale requirements and location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Job \"trainer_task_160921_225339\" was submitted successfully.<br/>Run \"%ml jobs --name trainer_task_160921_225339\" to view the status of the job.</p><p>Click <a href=\"https://console.developers.google.com/logs/viewer?project=cloud-ml-test-automated&resource=ml.googleapis.com%2Fjob_id%2Ftrainer_task_160921_225339\" target=\"_blank\">here</a> to view cloud log. <br/>Start TensorBoard by running \"%tensorboard start --logdir=&lt;YourLogDir&gt;\".</p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ml train --cloud\n",
    "package_uris: $package_path\n",
    "python_module: trainer.task\n",
    "scale_tier: BASIC\n",
    "region: us-central1\n",
    "args:\n",
    "  train_data_paths:\n",
    "    - $train_data_path\n",
    "  eval_data_paths:\n",
    "    - $eval_data_path\n",
    "  metadata_path: $metadata_path\n",
    "  output_path: $output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the job status as described in the output. You can also run \"%ml jobs --filter state!=SUCCEEDED\" to see all active ML jobs in that project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>createTime: '2016-09-21T22:53:40Z'\n",
       "endTime: '2016-09-21T23:00:29Z'\n",
       "jobId: trainer_task_160921_225339\n",
       "startTime: '2016-09-21T22:56:03Z'\n",
       "state: SUCCEEDED\n",
       "trainingInput:\n",
       "  args: [--train_data_paths, 'gs://cloud-ml-test-automated-sampledata/iris/preprocessed/features_train',\n",
       "    --metadata_path, 'gs://cloud-ml-test-automated-sampledata/iris/preprocessed/metadata.yaml',\n",
       "    --output_path, 'gs://cloud-ml-test-automated-sampledata/iris/trained', --eval_data_paths,\n",
       "    'gs://cloud-ml-test-automated-sampledata/iris/preprocessed/features_eval']\n",
       "  packageUris: ['gs://cloud-ml-test-automated-sampledata/iris/model/trainer-0.1.tar.gz']\n",
       "  pythonModule: trainer.task\n",
       "  region: us-central1\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ml jobs --name trainer_task_160921_225339"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the trained model once the state is 'SUCCEEDED':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-test-automated-sampledata/iris/trained/eval/\r\n",
      "gs://cloud-ml-test-automated-sampledata/iris/trained/logdir/\r\n",
      "gs://cloud-ml-test-automated-sampledata/iris/trained/model/\r\n",
      "gs://cloud-ml-test-automated-sampledata/iris/trained/summaries/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorBoard works with GCS path so it works with Cloud training too."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
