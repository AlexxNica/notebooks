{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Batch prediction and evaluation are very similar. They are based on DataFlow pipeline and CloudML provides Evaluate and Prediction DataFlow transform. Datalab can generate DataFlow pipeline code template for you, just like Preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run \"%ml evaluate\" to generate input cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%ml evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fill in the required fields, run it to generate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%ml evaluate\n",
    "preprocessed_eval_data_path: /content/datalab/tmp/ml/iris/preprocessed/features_eval\n",
    "metadata_path: /content/datalab/tmp/ml/iris/preprocessed/metadata.yaml\n",
    "model_dir: /content/datalab/tmp/ml/iris/model/model\n",
    "output_dir: /content/datalab/tmp/ml/iris/evaluate\n",
    "output_prediction_name: predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the generated code. Optionally uncomment the code for creating confusion matrix plot. Note that the confusionmatrix code is only generated in classification case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"115a5161-7224-4f25-be91-f07e9585cb40\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"115a5161-7224-4f25-be91-f07e9585cb40\", [{\"y\": [\"Iris-virginica\", \"Iris-versicolor\", \"Iris-setosa\"], \"x\": [\"Iris-virginica\", \"Iris-versicolor\", \"Iris-setosa\"], \"z\": [[6, 1, 0], [4, 7, 0], [0, 0, 12]], \"type\": \"heatmap\", \"colorscale\": \"YlGnBu\"}], {\"title\": \"Confusion Matrix\", \"xaxis\": {\"title\": \"Predicted value\"}, \"yaxis\": {\"title\": \"True Value\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# header\n",
    "\"\"\"\n",
    "Following code is generated from command line:\n",
    "%%ml evaluate\n",
    "preprocessed_eval_data_path: /content/datalab/tmp/ml/iris/preprocessed/features_eval\n",
    "metadata_path: /content/datalab/tmp/ml/iris/preprocessed/metadata.yaml\n",
    "model_dir: /content/datalab/tmp/ml/iris/model/model\n",
    "output_dir: /content/datalab/tmp/ml/iris/evaluate\n",
    "output_prediction_name: predictions\n",
    "\n",
    "Please modify as appropriate!!!\n",
    "\"\"\"\n",
    "\n",
    "# imports\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import fileio\n",
    "import google.cloud.ml as ml\n",
    "import google.cloud.ml.analysis as analysis\n",
    "import google.cloud.ml.dataflow.io.tfrecordio as tfrecordio\n",
    "import google.cloud.ml.io as io\n",
    "import json\n",
    "import os\n",
    "\n",
    "# defines\n",
    "def extract_values((example, prediction)):\n",
    "  import tensorflow as tf\n",
    "  tf_example = tf.train.Example()\n",
    "  tf_example.ParseFromString(example.values()[0])\n",
    "  feature_map = tf_example.features.feature\n",
    "  values = {'target': feature_map['species'].int64_list.value[0]}\n",
    "  values.update(prediction)\n",
    "  return values\n",
    "\n",
    "OUTPUT_DIR = '/content/datalab/tmp/ml/iris/evaluate'\n",
    "pipeline = beam.Pipeline('DirectPipelineRunner')\n",
    "\n",
    "\n",
    "# evaluation\n",
    "eval_data_source = tfrecordio.TFRecordSource('/content/datalab/tmp/ml/iris/preprocessed/features_eval', compression_type=fileio.CompressionTypes.ZLIB)\n",
    "eval_features = pipeline | eval_data_source\n",
    "trained_model = pipeline | io.LoadModel('LoadModel', '/content/datalab/tmp/ml/iris/model/model')\n",
    "evaluations = (eval_features | ml.Evaluate(trained_model, label='Evaluate')\n",
    "    | beam.Map('ExtractEvaluationResults', extract_values))\n",
    "eval_data_sink = beam.io.TextFileSink(os.path.join(OUTPUT_DIR, 'eval'))\n",
    "evaluations | beam.Write('WriteEval', eval_data_sink)\n",
    "\n",
    "# analysis\n",
    "def make_data_for_analysis(values):\n",
    "  return {\n",
    "      'target': values['target'],\n",
    "      'predicted': values['predictions'],\n",
    "      'score': 0.0,\n",
    "  }\n",
    "\n",
    "metadata = pipeline | io.LoadMetadata('/content/datalab/tmp/ml/iris/preprocessed/metadata.yaml')\n",
    "analysis_source = evaluations | beam.Map('CreateAnalysisSource', make_data_for_analysis)\n",
    "confusion_matrix, precision_recall, logloss = (analysis_source |\n",
    "    analysis.AnalyzeModel('Analyze Model', metadata))\n",
    "confusion_matrix_file = os.path.join(OUTPUT_DIR, 'analyze_cm.json')\n",
    "confusion_matrix_sink = beam.io.TextFileSink(confusion_matrix_file, shard_name_template='')\n",
    "confusion_matrix | beam.io.Write('WriteConfusionMatrix', confusion_matrix_sink)\n",
    "\n",
    "# run pipeline\n",
    "pipeline.run()\n",
    "\n",
    "# View Confusion Matrix with the following code:\n",
    "#\n",
    "import datalab.ml\n",
    "import yaml\n",
    "with ml.util._file.open_local_or_gcs(confusion_matrix_file, 'r') as f:\n",
    "  data = [yaml.load(line) for line in f.read().rstrip().split('\\n')]\n",
    "datalab.ml.ConfusionMatrix([d['predicted'] for d in data],\n",
    "                           [d['target'] for d in data],\n",
    "                           [d['count'] for d in data]).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a pipeline that runs in cloud, simply run \"%ml evaluate --cloud\". Also all paths need to be GCS paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "bucket = 'gs://' + datalab_project_id() + '-sampledata'\n",
    "eval_data_path = os.path.join(bucket, 'iris', 'preprocessed', 'features_eval')\n",
    "metadata_path = os.path.join(bucket, 'iris', 'preprocessed', 'metadata.yaml')\n",
    "model_path = os.path.join(bucket, 'iris', 'trained', 'model')\n",
    "output_dir = os.path.join(bucket, 'iris', 'evaluate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%ml evaluate --cloud\n",
    "preprocessed_eval_data_path: $eval_data_path\n",
    "metadata_path: $metadata_path\n",
    "model_dir: $model_path\n",
    "output_dir: $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DataflowPipelineResult <Job\n",
       " id: u'2016-08-31_22_41_30-12572926462340872569'\n",
       " projectId: u'cloud-ml-test-automated'\n",
       " steps: []\n",
       " tempFiles: []\n",
       " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)> at 0x7f5b606f0ed0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# header\n",
    "\"\"\"\n",
    "Following code is generated from command line:\n",
    "%%ml evaluate --cloud\n",
    "preprocessed_eval_data_path: $eval_data_path\n",
    "metadata_path: $metadata_path\n",
    "model_dir: $model_path\n",
    "output_dir: $output_dir\n",
    "\n",
    "Please modify as appropriate!!!\n",
    "\"\"\"\n",
    "\n",
    "# imports\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import fileio\n",
    "import google.cloud.ml as ml\n",
    "import google.cloud.ml.analysis as analysis\n",
    "import google.cloud.ml.dataflow.io.tfrecordio as tfrecordio\n",
    "import google.cloud.ml.io as io\n",
    "import json\n",
    "import os\n",
    "\n",
    "# defines\n",
    "def extract_values((example, prediction)):\n",
    "  import tensorflow as tf\n",
    "  tf_example = tf.train.Example()\n",
    "  tf_example.ParseFromString(example.values()[0])\n",
    "  feature_map = tf_example.features.feature\n",
    "  values = {'target': feature_map['species'].int64_list.value[0]}\n",
    "  values.update(prediction)\n",
    "  return values\n",
    "\n",
    "OUTPUT_DIR = 'gs://cloud-ml-test-automated-sampledata/iris/evaluate'\n",
    "import datetime\n",
    "options = {\n",
    "    'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "    'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "    'job_name': 'evaluate' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S'),\n",
    "    'project': 'cloud-ml-test-automated',\n",
    "    'extra_packages': ['gs://cloud-ml/sdk/cloudml-0.1.2.latest.tar.gz'],\n",
    "    'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "    'no_save_main_session': True\n",
    "}\n",
    "opts = beam.pipeline.PipelineOptions(flags=[], **options)\n",
    "pipeline = beam.Pipeline('DataflowPipelineRunner', options=opts)\n",
    "\n",
    "\n",
    "# evaluation\n",
    "eval_data_source = tfrecordio.TFRecordSource('gs://cloud-ml-test-automated-sampledata/iris/preprocessed/features_eval', compression_type=fileio.CompressionTypes.ZLIB)\n",
    "eval_features = pipeline | eval_data_source\n",
    "trained_model = pipeline | io.LoadModel('LoadModel', 'gs://cloud-ml-test-automated-sampledata/iris/trained/model')\n",
    "evaluations = (eval_features | ml.Evaluate(trained_model, label='Evaluate')\n",
    "    | beam.Map('ExtractEvaluationResults', extract_values))\n",
    "eval_data_sink = beam.io.TextFileSink(os.path.join(OUTPUT_DIR, 'eval'))\n",
    "evaluations | beam.Write('WriteEval', eval_data_sink)\n",
    "\n",
    "# analysis\n",
    "\n",
    "# run pipeline\n",
    "pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
