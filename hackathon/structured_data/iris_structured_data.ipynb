{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents\n",
    "===\n",
    "\n",
    "<a href=\"#about\">About this notebook</a> <br />\n",
    "<a href=\"#setup\">Setting things up</a>\n",
    "\n",
    "Local Experience\n",
    "1. <a href=\"#local_preprocessing\">Local preprocessing starting from csv files</a>\n",
    "1. <a href=\"#local_training\">Local training</a>\n",
    "1. <a href=\"#local_prediction\">Local prediction</a>\n",
    "1. <a href=\"#local_batch_prediction\">Local batch prediction</a>\n",
    "\n",
    "Cloud Experience\n",
    "1. <a href=\"#cloud_preprocessing\">Cloud preprocessing starting from csv files</a>\n",
    "1. <a href=\"#cloud_training\">Cloud training</a>\n",
    "1. <a href=\"#cloud_online_prediction\">Cloud prediction</a>\n",
    "1. <a href=\"#cloud_batch_prediction\">Clod batch prediction</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"about\"></a>\n",
    "About this notebook\n",
    "======\n",
    "\n",
    "This notebook uses the datalab structured data package for building and running a Tensorflow classification problems locally, and using Google Compute Platform services. This notebook uses the classic <a href=\"https://en.wikipedia.org/wiki/Iris_flower_data_set\">Iris flower data set.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "Setting things up\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%projects set cloud-ml-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project cloud-ml-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set compute/region us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added serviceAccount:cloud-ml-service@cml-236417448818.iam.gserviceaccount.com as an Editor to project 'cloud-ml-dev'.\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ml init-project -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Collecting tensorflow==1.0.0',\n",
       " '  Using cached tensorflow-1.0.0-cp27-cp27mu-manylinux1_x86_64.whl',\n",
       " 'Requirement already up-to-date: numpy>=1.11.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.0.0)',\n",
       " 'Requirement already up-to-date: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.0.0)',\n",
       " 'Requirement already up-to-date: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.0.0)',\n",
       " 'Requirement already up-to-date: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.0.0)',\n",
       " 'Requirement already up-to-date: protobuf>=3.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.0.0)',\n",
       " 'Requirement already up-to-date: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.0.0)',\n",
       " 'Requirement already up-to-date: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.0.0)',\n",
       " 'Requirement already up-to-date: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.1.0->tensorflow==1.0.0)',\n",
       " 'Requirement already up-to-date: packaging>=16.8 in /usr/local/lib/python2.7/dist-packages (from setuptools->protobuf>=3.1.0->tensorflow==1.0.0)',\n",
       " 'Requirement already up-to-date: appdirs>=1.4.0 in /usr/local/lib/python2.7/dist-packages (from setuptools->protobuf>=3.1.0->tensorflow==1.0.0)',\n",
       " 'Requirement already up-to-date: pyparsing in /usr/local/lib/python2.7/dist-packages (from packaging>=16.8->setuptools->protobuf>=3.1.0->tensorflow==1.0.0)',\n",
       " 'Installing collected packages: tensorflow',\n",
       " '  Found existing installation: tensorflow 0.12.1',\n",
       " '    Uninstalling tensorflow-0.12.1:',\n",
       " '      Successfully uninstalled tensorflow-0.12.1',\n",
       " 'Successfully installed tensorflow-1.0.0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -U tensorflow==0.12.1\n",
    "#!wget https://storage.googleapis.com/cloud-datalab/deploy/tf/tensorflow-1.0.0rc1-cp27-none-linux_x86_64.whl && \\\n",
    "#   pip install --upgrade-strategy only-if-needed --no-cache-dir tensorflow-1.0.0rc1-cp27-none-linux_x86_64.whl && \\\n",
    "#   rm tensorflow-1.0.0rc1-cp27-none-linux_x86_64.whl\n",
    "#!pip install --upgrade --force-reinstall /content/pydatalab/solutionbox/structured_data/dist/structured_data-0.0.1.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import datalab_solutions.structured_data as sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the versions of structured_data and TF we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf 0.12.1\n",
      "sd 0.0.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "print('tf ' + str(tf.__version__))\n",
    "print('sd ' + str(sd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will write files during preprocessing, training, and prediction. Please give a root folder you wish to write use for local and cloud usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LOCAL_ROOT = '/content/Downloads/iris_notebook_workspace'\n",
    "if not os.path.exists(LOCAL_ROOT):\n",
    "  os.mkdirs(LOCAL_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CLOUD_ROOT = 'gs://cloud-ml-dev_bdt/iris_notebook_workspace'\n",
    "from tensorflow.python.lib.io import file_io\n",
    "if not file_io.file_exists(CLOUD_ROOT):\n",
    "  file_io.recursive_create_dir(CLOUD_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iris dataset is small, so the data is embedded into this notebook. Write the iris data set into 3 files: training, eval, prediction. Note that the target column has to be the first column in the dataset. Also, the prediction dataset does not have target values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/Downloads/iris_notebook_workspace/train.csv\n"
     ]
    }
   ],
   "source": [
    "%writefile {LOCAL_ROOT}/train.csv\n",
    "Iris-setosa,4,4.6,3.1,1.5,0.2\n",
    "Iris-setosa,20,5.1,3.8,1.5,0.3\n",
    "Iris-setosa,43,4.4,3.2,1.3,0.2\n",
    "Iris-versicolor,88,6.3,2.3,4.4,1.3\n",
    "Iris-versicolor,76,6.6,3,4.4,1.4\n",
    "Iris-versicolor,63,6,2.2,4,1\n",
    "Iris-setosa,47,5.1,3.8,1.6,0.2\n",
    "Iris-virginica,146,6.7,3,5.2,2.3\n",
    "Iris-versicolor,53,6.9,3.1,4.9,1.5\n",
    "Iris-versicolor,71,5.9,3.2,4.8,1.8\n",
    "Iris-virginica,144,6.8,3.2,5.9,2.3\n",
    "Iris-virginica,124,6.3,2.7,4.9,1.8\n",
    "Iris-virginica,122,5.6,2.8,4.9,2\n",
    "Iris-setosa,17,5.4,3.9,1.3,0.4\n",
    "Iris-setosa,7,4.6,3.4,1.4,0.3\n",
    "Iris-versicolor,87,6.7,3.1,4.7,1.5\n",
    "Iris-virginica,131,7.4,2.8,6.1,1.9\n",
    "Iris-setosa,2,4.9,3,1.4,0.2\n",
    "Iris-virginica,147,6.3,2.5,5,1.9\n",
    "Iris-setosa,29,5.2,3.4,1.4,0.2\n",
    "Iris-versicolor,91,5.5,2.6,4.4,1.2\n",
    "Iris-virginica,110,7.2,3.6,6.1,2.5\n",
    "Iris-virginica,121,6.9,3.2,5.7,2.3\n",
    "Iris-setosa,45,5.1,3.8,1.9,0.4\n",
    "Iris-setosa,10,4.9,3.1,1.5,0.1\n",
    "Iris-setosa,36,5,3.2,1.2,0.2\n",
    "Iris-virginica,112,6.4,2.7,5.3,1.9\n",
    "Iris-setosa,46,4.8,3,1.4,0.3\n",
    "Iris-virginica,132,7.9,3.8,6.4,2\n",
    "Iris-versicolor,77,6.8,2.8,4.8,1.4\n",
    "Iris-setosa,6,5.4,3.9,1.7,0.4\n",
    "Iris-versicolor,90,5.5,2.5,4,1.3\n",
    "Iris-virginica,137,6.3,3.4,5.6,2.4\n",
    "Iris-setosa,31,4.8,3.1,1.6,0.2\n",
    "Iris-virginica,120,6,2.2,5,1.5\n",
    "Iris-virginica,138,6.4,3.1,5.5,1.8\n",
    "Iris-setosa,24,5.1,3.3,1.7,0.5\n",
    "Iris-versicolor,96,5.7,3,4.2,1.2\n",
    "Iris-versicolor,68,5.8,2.7,4.1,1\n",
    "Iris-virginica,150,5.9,3,5.1,1.8\n",
    "Iris-setosa,26,5,3,1.6,0.2\n",
    "Iris-versicolor,98,6.2,2.9,4.3,1.3\n",
    "Iris-versicolor,80,5.7,2.6,3.5,1\n",
    "Iris-versicolor,72,6.1,2.8,4,1.3\n",
    "Iris-versicolor,75,6.4,2.9,4.3,1.3\n",
    "Iris-setosa,38,4.9,3.1,1.5,0.1\n",
    "Iris-setosa,35,4.9,3.1,1.5,0.1\n",
    "Iris-versicolor,89,5.6,3,4.1,1.3\n",
    "Iris-versicolor,84,6,2.7,5.1,1.6\n",
    "Iris-versicolor,51,7,3.2,4.7,1.4\n",
    "Iris-virginica,116,6.4,3.2,5.3,2.3\n",
    "Iris-versicolor,54,5.5,2.3,4,1.3\n",
    "Iris-virginica,130,7.2,3,5.8,1.6\n",
    "Iris-virginica,115,5.8,2.8,5.1,2.4\n",
    "Iris-setosa,32,5.4,3.4,1.5,0.4\n",
    "Iris-virginica,104,6.3,2.9,5.6,1.8\n",
    "Iris-versicolor,64,6.1,2.9,4.7,1.4\n",
    "Iris-setosa,18,5.1,3.5,1.4,0.3\n",
    "Iris-versicolor,66,6.7,3.1,4.4,1.4\n",
    "Iris-setosa,15,5.8,4,1.2,0.2\n",
    "Iris-versicolor,52,6.4,3.2,4.5,1.5\n",
    "Iris-virginica,103,7.1,3,5.9,2.1\n",
    "Iris-setosa,9,4.4,2.9,1.4,0.2\n",
    "Iris-versicolor,83,5.8,2.7,3.9,1.2\n",
    "Iris-virginica,135,6.1,2.6,5.6,1.4\n",
    "Iris-virginica,139,6,3,4.8,1.8\n",
    "Iris-versicolor,85,5.4,3,4.5,1.5\n",
    "Iris-virginica,106,7.6,3,6.6,2.1\n",
    "Iris-setosa,27,5,3.4,1.6,0.4\n",
    "Iris-virginica,140,6.9,3.1,5.4,2.1\n",
    "Iris-versicolor,67,5.6,3,4.5,1.5\n",
    "Iris-setosa,12,4.8,3.4,1.6,0.2\n",
    "Iris-versicolor,56,5.7,2.8,4.5,1.3\n",
    "Iris-virginica,113,6.8,3,5.5,2.1\n",
    "Iris-versicolor,62,5.9,3,4.2,1.5\n",
    "Iris-virginica,145,6.7,3.3,5.7,2.5\n",
    "Iris-virginica,111,6.5,3.2,5.1,2\n",
    "Iris-virginica,141,6.7,3.1,5.6,2.4\n",
    "Iris-setosa,34,5.5,4.2,1.4,0.2\n",
    "Iris-versicolor,81,5.5,2.4,3.8,1.1\n",
    "Iris-setosa,8,5,3.4,1.5,0.2\n",
    "Iris-virginica,129,6.4,2.8,5.6,2.1\n",
    "Iris-versicolor,57,6.3,3.3,4.7,1.6\n",
    "Iris-virginica,128,6.1,3,4.9,1.8\n",
    "Iris-virginica,119,7.7,2.6,6.9,2.3\n",
    "Iris-virginica,126,7.2,3.2,6,1.8\n",
    "Iris-versicolor,58,4.9,2.4,3.3,1\n",
    "Iris-virginica,117,6.5,3,5.5,1.8\n",
    "Iris-virginica,127,6.2,2.8,4.8,1.8\n",
    "Iris-setosa,16,5.7,4.4,1.5,0.4\n",
    "Iris-setosa,3,4.7,3.2,1.3,0.2\n",
    "Iris-virginica,108,7.3,2.9,6.3,1.8\n",
    "Iris-virginica,118,7.7,3.8,6.7,2.2\n",
    "Iris-setosa,42,4.5,2.3,1.3,0.3\n",
    "Iris-virginica,142,6.9,3.1,5.1,2.3\n",
    "Iris-setosa,14,4.3,3,1.1,0.1\n",
    "Iris-virginica,134,6.3,2.8,5.1,1.5\n",
    "Iris-versicolor,94,5,2.3,3.3,1\n",
    "Iris-setosa,19,5.7,3.8,1.7,0.3\n",
    "Iris-virginica,133,6.4,2.8,5.6,2.2\n",
    "Iris-virginica,114,5.7,2.5,5,2\n",
    "Iris-versicolor,86,6,3.4,4.5,1.6\n",
    "Iris-versicolor,93,5.8,2.6,4,1.2\n",
    "Iris-versicolor,92,6.1,3,4.6,1.4\n",
    "Iris-virginica,109,6.7,2.5,5.8,1.8\n",
    "Iris-virginica,102,5.8,2.7,5.1,1.9\n",
    "Iris-setosa,41,5,3.5,1.3,0.3\n",
    "Iris-versicolor,60,5.2,2.7,3.9,1.4\n",
    "Iris-virginica,105,6.5,3,5.8,2.2\n",
    "Iris-versicolor,65,5.6,2.9,3.6,1.3\n",
    "Iris-setosa,28,5.2,3.5,1.5,0.2\n",
    "Iris-versicolor,82,5.5,2.4,3.7,1\n",
    "Iris-setosa,25,4.8,3.4,1.9,0.2\n",
    "Iris-versicolor,79,6,2.9,4.5,1.5\n",
    "Iris-setosa,1,5.1,3.5,1.4,0.2\n",
    "Iris-versicolor,61,5,2,3.5,1\n",
    "Iris-virginica,149,6.2,3.4,5.4,2.3\n",
    "Iris-setosa,48,4.6,3.2,1.4,0.2\n",
    "Iris-setosa,22,5.1,3.7,1.5,0.4\n",
    "Iris-setosa,30,4.7,3.2,1.6,0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/Downloads/iris_notebook_workspace/eval.csv\n"
     ]
    }
   ],
   "source": [
    "%writefile {LOCAL_ROOT}/eval.csv\n",
    "Iris-virginica,107,4.9,2.5,4.5,1.7\n",
    "Iris-versicolor,100,5.7,2.8,4.1,1.3\n",
    "Iris-versicolor,99,5.1,2.5,3,1.1\n",
    "Iris-setosa,13,4.8,3,1.4,0.1\n",
    "Iris-versicolor,70,5.6,2.5,3.9,1.1\n",
    "Iris-setosa,11,5.4,3.7,1.5,0.2\n",
    "Iris-setosa,37,5.5,3.5,1.3,0.2\n",
    "Iris-versicolor,69,6.2,2.2,4.5,1.5\n",
    "Iris-setosa,40,5.1,3.4,1.5,0.2\n",
    "Iris-virginica,101,6.3,3.3,6,2.5\n",
    "Iris-setosa,39,4.4,3,1.3,0.2\n",
    "Iris-versicolor,74,6.1,2.8,4.7,1.2\n",
    "Iris-versicolor,97,5.7,2.9,4.2,1.3\n",
    "Iris-setosa,50,5,3.3,1.4,0.2\n",
    "Iris-versicolor,95,5.6,2.7,4.2,1.3\n",
    "Iris-setosa,44,5,3.5,1.6,0.6\n",
    "Iris-virginica,123,7.7,2.8,6.7,2\n",
    "Iris-setosa,23,4.6,3.6,1,0.2\n",
    "Iris-versicolor,59,6.6,2.9,4.6,1.3\n",
    "Iris-virginica,148,6.5,3,5.2,2\n",
    "Iris-versicolor,55,6.5,2.8,4.6,1.5\n",
    "Iris-setosa,49,5.3,3.7,1.5,0.2\n",
    "Iris-versicolor,78,6.7,3,5,1.7\n",
    "Iris-versicolor,73,6.3,2.5,4.9,1.5\n",
    "Iris-virginica,136,7.7,3,6.1,2.3\n",
    "Iris-setosa,33,5.2,4.1,1.5,0.1\n",
    "Iris-virginica,125,6.7,3.3,5.7,2.1\n",
    "Iris-virginica,143,5.8,2.7,5.1,1.9\n",
    "Iris-setosa,21,5.4,3.4,1.7,0.2\n",
    "Iris-setosa,5,5,3.6,1.4,0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/Downloads/iris_notebook_workspace/predict.csv\n"
     ]
    }
   ],
   "source": [
    "%writefile {LOCAL_ROOT}/predict.csv\n",
    "107,4.9,2.5,4.5,1.7\n",
    "100,5.7,2.8,4.1,1.3\n",
    "99,5.1,2.5,3,1.1\n",
    "13,4.8,3,1.4,0.1\n",
    "70,5.6,2.5,3.9,1.1\n",
    "11,5.4,3.7,1.5,0.2\n",
    "37,5.5,3.5,1.3,0.2\n",
    "69,6.2,2.2,4.5,1.5\n",
    "40,5.1,3.4,1.5,0.2\n",
    "101,6.3,3.3,6,2.5\n",
    "39,4.4,3,1.3,0.2\n",
    "74,6.1,2.8,4.7,1.2\n",
    "97,5.7,2.9,4.2,1.3\n",
    "50,5,3.3,1.4,0.2\n",
    "95,5.6,2.7,4.2,1.3\n",
    "44,5,3.5,1.6,0.6\n",
    "123,7.7,2.8,6.7,2\n",
    "23,4.6,3.6,1,0.2\n",
    "59,6.6,2.9,4.6,1.3\n",
    "148,6.5,3,5.2,2\n",
    "55,6.5,2.8,4.6,1.5\n",
    "49,5.3,3.7,1.5,0.2\n",
    "78,6.7,3,5,1.7\n",
    "73,6.3,2.5,4.9,1.5\n",
    "136,7.7,3,6.1,2.3\n",
    "33,5.2,4.1,1.5,0.1\n",
    "125,6.7,3.3,5.7,2.1\n",
    "143,5.8,2.7,5.1,1.9\n",
    "21,5.4,3.4,1.7,0.2\n",
    "5,5,3.6,1.4,0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"local_preprocessing\"></a>\n",
    "Local preprocessing starting from csv files\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A schema file is used to describe each column of the csv files. It is assumed that the train, eval, and prediction csv files all have the same schema, but the prediction file is allowed to have a missing target column. The format of the  schema file is a valid BigQuery table schema file. This allows BigQuery to be used later in cloud preprocessing. Only 3 BigQuery types are supported: STRING (for categorical columns) and INTEGER and FLOAT (for numerical columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/Downloads/iris_notebook_workspace/schema.json\n"
     ]
    }
   ],
   "source": [
    "%writefile {LOCAL_ROOT}/schema.json\n",
    "[\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"flower\",\n",
    "        \"type\": \"STRING\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"REQUIRED\",\n",
    "        \"name\": \"key\",\n",
    "        \"type\": \"INTEGER\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"sepal_length\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"sepal_width\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"petal_length\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    },\n",
    "    {\n",
    "        \"mode\": \"NULLABLE\",\n",
    "        \"name\": \"petal_width\",\n",
    "        \"type\": \"FLOAT\"\n",
    "    }   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/content/Downloads/iris_notebook_workspace/preprocess': Is a directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -f {LOCAL_ROOT}/preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting local preprocessing.\n",
      "Local preprocessing done.\n"
     ]
    }
   ],
   "source": [
    "sd.local_preprocess(\n",
    "  input_file_pattern=os.path.join(LOCAL_ROOT, 'train.*'),\n",
    "  output_dir=os.path.join(LOCAL_ROOT, 'preprocess'),\n",
    "  schema_file=os.path.join(LOCAL_ROOT, 'schema.json'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of preprocessing is a numerical_analysis file that contains analysis from the numerical columns, and a vocab file from each categorical column. The files preoduced by preprocessing are consumed in training, and you should not have to worry about these files. Just for fun, lets look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_analysis.json  schema.json  vocab_flower.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls  {LOCAL_ROOT}/preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"sepal_width\": {\r\n",
      "    \"max\": 4.4,\r\n",
      "    \"mean\": 3.050833333333332,\r\n",
      "    \"min\": 2.0\r\n",
      "  },\r\n",
      "  \"petal_width\": {\r\n",
      "    \"max\": 2.5,\r\n",
      "    \"mean\": 1.2324999999999995,\r\n",
      "    \"min\": 0.1\r\n",
      "  },\r\n",
      "  \"sepal_length\": {\r\n",
      "    \"max\": 7.9,\r\n",
      "    \"mean\": 5.867500000000002,\r\n",
      "    \"min\": 4.3\r\n",
      "  },\r\n",
      "  \"key\": {\r\n",
      "    \"max\": 150.0,\r\n",
      "    \"mean\": 76.73333333333333,\r\n",
      "    \"min\": 1.0\r\n",
      "  },\r\n",
      "  \"petal_length\": {\r\n",
      "    \"max\": 6.9,\r\n",
      "    \"mean\": 3.830833333333335,\r\n",
      "    \"min\": 1.1\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat {LOCAL_ROOT}/preprocess/numerical_analysis.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "    {\r\n",
      "        \"mode\": \"NULLABLE\",\r\n",
      "        \"name\": \"flower\",\r\n",
      "        \"type\": \"STRING\"\r\n",
      "    },\r\n",
      "    {\r\n",
      "        \"mode\": \"REQUIRED\",\r\n",
      "        \"name\": \"key\",\r\n",
      "        \"type\": \"INTEGER\"\r\n",
      "    },\r\n",
      "    {\r\n",
      "        \"mode\": \"NULLABLE\",\r\n",
      "        \"name\": \"sepal_length\",\r\n",
      "        \"type\": \"FLOAT\"\r\n",
      "    },\r\n",
      "    {\r\n",
      "        \"mode\": \"NULLABLE\",\r\n",
      "        \"name\": \"sepal_width\",\r\n",
      "        \"type\": \"FLOAT\"\r\n",
      "    },\r\n",
      "    {\r\n",
      "        \"mode\": \"NULLABLE\",\r\n",
      "        \"name\": \"petal_length\",\r\n",
      "        \"type\": \"FLOAT\"\r\n",
      "    },\r\n",
      "    {\r\n",
      "        \"mode\": \"NULLABLE\",\r\n",
      "        \"name\": \"petal_width\",\r\n",
      "        \"type\": \"FLOAT\"\r\n",
      "    }   \r\n",
      "]"
     ]
    }
   ],
   "source": [
    "!cat {LOCAL_ROOT}/preprocess/schema.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-virginica\r\n",
      "Iris-setosa\r\n",
      "Iris-versicolor"
     ]
    }
   ],
   "source": [
    "!cat {LOCAL_ROOT}/preprocess/vocab_flower.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"local_training\"></a>\n",
    "Local Training\n",
    "==========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files in the output folder of preprocessing is consumed by the trainer. The structured data package will automatically pick transforms to perform on each column of data depending on the problem and the data type. Lets first run the trainer with all the defaults. When using all the defaults the key_column parameter must be used to tell which column is the key column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -fr {LOCAL_ROOT}/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting local training.\n",
      "INFO:tensorflow:Using config: {'save_summary_steps': 100, '_num_ps_replicas': 0, '_task_type': None, '_environment': 'local', '_is_chief': True, 'save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fde24057b10>, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_id': 0, 'tf_random_seed': None, 'keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', 'save_checkpoints_steps': None, '_master': '', 'keep_checkpoint_max': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'save_summary_steps': 100, '_num_ps_replicas': 0, '_task_type': None, '_environment': 'local', '_is_chief': True, 'save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fde24057b10>, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_id': 0, 'tf_random_seed': None, 'keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', 'save_checkpoints_steps': None, '_master': '', 'keep_checkpoint_max': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:322 in __init__.: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:322 in __init__.: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/datalab_solutions/structured_data/trainer/task.py:320 in get_experiment.: calling __init__ (from tensorflow.contrib.learn.python.learn.experiment) with local_eval_frequency=None is deprecated and will be removed after 2016-10-23.\n",
      "Instructions for updating:\n",
      "local_eval_frequency is deprecated as local_run will be renamed to train_and_evaluate. Use min_eval_frequency and call train_and_evaluate instead. Note, however, that the default for min_eval_frequency is 1, meaning models will be evaluated every time a new checkpoint is available. In contrast, the default for local_eval_frequency is None, resulting in evaluation occurring only after training has completed. min_eval_frequency is ignored when calling the deprecated local_run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/datalab_solutions/structured_data/trainer/task.py:320 in get_experiment.: calling __init__ (from tensorflow.contrib.learn.python.learn.experiment) with local_eval_frequency=None is deprecated and will be removed after 2016-10-23.\n",
      "Instructions for updating:\n",
      "local_eval_frequency is deprecated as local_run will be renamed to train_and_evaluate. Use min_eval_frequency and call train_and_evaluate instead. Note, however, that the default for min_eval_frequency is 1, meaning models will be evaluated every time a new checkpoint is available. In contrast, the default for local_eval_frequency is None, resulting in evaluation occurring only after training has completed. min_eval_frequency is ignored when calling the deprecated local_run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:322 in __init__.: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:322 in __init__.: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.38405, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.38405, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /content/Downloads/iris_notebook_workspace/training/train/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /content/Downloads/iris_notebook_workspace/training/train/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/Downloads/iris_notebook_workspace/training/intermediate_models/00000001-tmp/export is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/Downloads/iris_notebook_workspace/training/intermediate_models/00000001-tmp/export is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.529453, step = 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.529453, step = 101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 41.0711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 41.0711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0818374, step = 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0818374, step = 201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 48.5422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 48.5422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 250 into /content/Downloads/iris_notebook_workspace/training/train/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 250 into /content/Downloads/iris_notebook_workspace/training/train/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/Downloads/iris_notebook_workspace/training/intermediate_models/00000250-tmp/export is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/Downloads/iris_notebook_workspace/training/intermediate_models/00000250-tmp/export is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.0775295.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.0775295.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please specify metrics using MetricSpec. Using bare functions or (key, fn) tuples is deprecated and support for it will be removed on Oct 1, 2016.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please specify metrics using MetricSpec. Using bare functions or (key, fn) tuples is deprecated and support for it will be removed on Oct 1, 2016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /content/Downloads/iris_notebook_workspace/training/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /content/Downloads/iris_notebook_workspace/training/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Eval steps [0,100) for training step 250.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Eval steps [0,100) for training step 250.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 10 steps (0.004 sec/batch): accuracy = 0.933, loss = 0.20425.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 10 steps (0.004 sec/batch): accuracy = 0.933, loss = 0.20425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 20 steps (0.004 sec/batch): accuracy = 0.9335, loss = 0.202992.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 20 steps (0.004 sec/batch): accuracy = 0.9335, loss = 0.202992.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 30 steps (0.003 sec/batch): accuracy = 0.933333, loss = 0.20353.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 30 steps (0.003 sec/batch): accuracy = 0.933333, loss = 0.20353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 40 steps (0.003 sec/batch): accuracy = 0.93325, loss = 0.20371.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 40 steps (0.003 sec/batch): accuracy = 0.93325, loss = 0.20371.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 50 steps (0.003 sec/batch): accuracy = 0.9334, loss = 0.203315.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 50 steps (0.003 sec/batch): accuracy = 0.9334, loss = 0.203315.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 60 steps (0.003 sec/batch): accuracy = 0.933333, loss = 0.20353.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 60 steps (0.003 sec/batch): accuracy = 0.933333, loss = 0.20353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 70 steps (0.002 sec/batch): accuracy = 0.933286, loss = 0.203633.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 70 steps (0.002 sec/batch): accuracy = 0.933286, loss = 0.203633.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 80 steps (0.002 sec/batch): accuracy = 0.933375, loss = 0.203396.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 80 steps (0.002 sec/batch): accuracy = 0.933375, loss = 0.203396.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 90 steps (0.003 sec/batch): accuracy = 0.933333, loss = 0.20353.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 90 steps (0.003 sec/batch): accuracy = 0.933333, loss = 0.20353.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 100 steps (0.003 sec/batch): accuracy = 0.9333, loss = 0.203602.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 100 steps (0.003 sec/batch): accuracy = 0.9333, loss = 0.203602.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Run call was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Coordinator didn't stop cleanly: Run call was cancelled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Coordinator didn't stop cleanly: Run call was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving evaluation summary for step 250: accuracy = 0.9333, loss = 0.203602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving evaluation summary for step 250: accuracy = 0.9333, loss = 0.203602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local training done.\n"
     ]
    }
   ],
   "source": [
    "sd.local_train(\n",
    "  train_file_pattern=os.path.join(LOCAL_ROOT, 'train.*'),\n",
    "  eval_file_pattern=os.path.join(LOCAL_ROOT, 'eval.*'),\n",
    "  preprocess_output_dir=os.path.join(LOCAL_ROOT, 'preprocess'),\n",
    "  output_dir=os.path.join(LOCAL_ROOT, 'training'),\n",
    "  key_column='key',\n",
    "  model_type='dnn_classification',\n",
    "  top_n=3,\n",
    "  max_steps=250,\n",
    "  layer_sizes=[10, 8, 5]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hum, iris is an easy problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, an accuracy of ~0.86 is not bad. Lets see if we can do better. For this we need to pass a some transform configureation in the form of a json transfrom file. See the doc string of local_train for a description of the transforms supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /content/Downloads/iris_notebook_workspace/transforms.json\n"
     ]
    }
   ],
   "source": [
    "%writefile {LOCAL_ROOT}/transforms.json\n",
    "{\n",
    "  \"sepal_length\": {\"transform\": \"scale\"},\n",
    "  \"sepal_width\": {\"transform\": \"scale\", \"value\": 4},\n",
    "  \"petal_length\": {\"transform\": \"scale\", \"default\": 0},\n",
    "  \"petal_width\": {\"transform\": \"scale\"},\n",
    "  \"key\": {\"transform\": \"key\"}\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -fr {LOCAL_ROOT}/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "hiddenCell": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting local training.\n",
      "INFO:tensorflow:Using config: {'save_summary_steps': 100, '_num_ps_replicas': 0, '_task_type': None, '_environment': 'local', '_is_chief': True, 'save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fde1593b6d0>, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_id': 0, 'tf_random_seed': None, 'keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', 'save_checkpoints_steps': None, '_master': '', 'keep_checkpoint_max': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'save_summary_steps': 100, '_num_ps_replicas': 0, '_task_type': None, '_environment': 'local', '_is_chief': True, 'save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fde1593b6d0>, 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_task_id': 0, 'tf_random_seed': None, 'keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', 'save_checkpoints_steps': None, '_master': '', 'keep_checkpoint_max': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:322 in __init__.: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:322 in __init__.: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/datalab_solutions/structured_data/trainer/task.py:320 in get_experiment.: calling __init__ (from tensorflow.contrib.learn.python.learn.experiment) with local_eval_frequency=None is deprecated and will be removed after 2016-10-23.\n",
      "Instructions for updating:\n",
      "local_eval_frequency is deprecated as local_run will be renamed to train_and_evaluate. Use min_eval_frequency and call train_and_evaluate instead. Note, however, that the default for min_eval_frequency is 1, meaning models will be evaluated every time a new checkpoint is available. In contrast, the default for local_eval_frequency is None, resulting in evaluation occurring only after training has completed. min_eval_frequency is ignored when calling the deprecated local_run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/datalab_solutions/structured_data/trainer/task.py:320 in get_experiment.: calling __init__ (from tensorflow.contrib.learn.python.learn.experiment) with local_eval_frequency=None is deprecated and will be removed after 2016-10-23.\n",
      "Instructions for updating:\n",
      "local_eval_frequency is deprecated as local_run will be renamed to train_and_evaluate. Use min_eval_frequency and call train_and_evaluate instead. Note, however, that the default for min_eval_frequency is 1, meaning models will be evaluated every time a new checkpoint is available. In contrast, the default for local_eval_frequency is None, resulting in evaluation occurring only after training has completed. min_eval_frequency is ignored when calling the deprecated local_run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:322 in __init__.: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/monitors.py:322 in __init__.: __init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.13006, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.13006, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /content/Downloads/iris_notebook_workspace/training/train/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into /content/Downloads/iris_notebook_workspace/training/train/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/Downloads/iris_notebook_workspace/training/intermediate_models/00000001-tmp/export is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/Downloads/iris_notebook_workspace/training/intermediate_models/00000001-tmp/export is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0290386, step = 101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0290386, step = 101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 42.9038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 42.9038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.022508, step = 201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.022508, step = 201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 50.6452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 50.6452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 250 into /content/Downloads/iris_notebook_workspace/training/train/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 250 into /content/Downloads/iris_notebook_workspace/training/train/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:now on by default.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:*******************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/Downloads/iris_notebook_workspace/training/intermediate_models/00000250-tmp/export is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:/content/Downloads/iris_notebook_workspace/training/intermediate_models/00000250-tmp/export is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.023279.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.023279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.\n",
      "Instructions for updating:\n",
      "Estimator is decoupled from Scikit Learn interface by moving into\n",
      "separate class SKCompat. Arguments x, y and batch_size are only\n",
      "available in the SKCompat class, Estimator will only accept input_fn.\n",
      "Example conversion:\n",
      "  est = Estimator(...) -> est = SKCompat(Estimator(...))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:fraction_of_zero_values is illegal; using dnn/hiddenlayer_2_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/hiddenlayer_2:activation is illegal; using dnn/hiddenlayer_2_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:fraction_of_zero_values is illegal; using dnn/logits_fraction_of_zero_values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name dnn/logits:activation is illegal; using dnn/logits_activation instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please specify metrics using MetricSpec. Using bare functions or (key, fn) tuples is deprecated and support for it will be removed on Oct 1, 2016.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please specify metrics using MetricSpec. Using bare functions or (key, fn) tuples is deprecated and support for it will be removed on Oct 1, 2016.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /content/Downloads/iris_notebook_workspace/training/train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restored model from /content/Downloads/iris_notebook_workspace/training/train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Eval steps [0,100) for training step 250.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Eval steps [0,100) for training step 250.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 10 steps (0.005 sec/batch): accuracy = 0.9, loss = 0.334344.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 10 steps (0.005 sec/batch): accuracy = 0.9, loss = 0.334344.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 20 steps (0.003 sec/batch): accuracy = 0.9005, loss = 0.331383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 20 steps (0.003 sec/batch): accuracy = 0.9005, loss = 0.331383.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 30 steps (0.003 sec/batch): accuracy = 0.9, loss = 0.331736.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 30 steps (0.003 sec/batch): accuracy = 0.9, loss = 0.331736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 40 steps (0.002 sec/batch): accuracy = 0.9, loss = 0.332388.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 40 steps (0.002 sec/batch): accuracy = 0.9, loss = 0.332388.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 50 steps (0.002 sec/batch): accuracy = 0.9002, loss = 0.331595.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 50 steps (0.002 sec/batch): accuracy = 0.9002, loss = 0.331595.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 60 steps (0.002 sec/batch): accuracy = 0.9, loss = 0.331736.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 60 steps (0.002 sec/batch): accuracy = 0.9, loss = 0.331736.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 70 steps (0.004 sec/batch): accuracy = 0.9, loss = 0.332109.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 70 steps (0.004 sec/batch): accuracy = 0.9, loss = 0.332109.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 80 steps (0.003 sec/batch): accuracy = 0.900125, loss = 0.331648.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 80 steps (0.003 sec/batch): accuracy = 0.900125, loss = 0.331648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 90 steps (0.002 sec/batch): accuracy = 0.9, loss = 0.331737.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 90 steps (0.002 sec/batch): accuracy = 0.9, loss = 0.331737.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 100 steps (0.002 sec/batch): accuracy = 0.9, loss = 0.331997.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Results after 100 steps (0.002 sec/batch): accuracy = 0.9, loss = 0.331997.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving evaluation summary for step 250: accuracy = 0.9, loss = 0.331997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving evaluation summary for step 250: accuracy = 0.9, loss = 0.331997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local training done.\n"
     ]
    }
   ],
   "source": [
    "sd.local_train(\n",
    "  train_file_pattern=os.path.join(LOCAL_ROOT, 'train.*'),\n",
    "  eval_file_pattern=os.path.join(LOCAL_ROOT, 'eval.*'),\n",
    "  preprocess_output_dir=os.path.join(LOCAL_ROOT, 'preprocess'),\n",
    "  output_dir=os.path.join(LOCAL_ROOT, 'training'),\n",
    "  transforms_file=os.path.join(LOCAL_ROOT, 'transforms.json'),\n",
    "  model_type='dnn_classification',\n",
    "  top_n=3,\n",
    "  max_steps=250,\n",
    "  layer_sizes=[10, 8, 5]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gained ~0.1 accuracy by just scaling the numbers! Try playing with other transforms. The output of training contains some folders. The final model used for prediction is saved in {LOCAL_ROOT}/training/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/Downloads/iris_notebook_workspace/training/intermediate_models:\r\n",
      "00000001  00000250\r\n",
      "\r\n",
      "/content/Downloads/iris_notebook_workspace/training/model:\r\n",
      "checkpoint  export  export.meta  schema.json  transforms.json  vocab_flower.csv\r\n",
      "\r\n",
      "/content/Downloads/iris_notebook_workspace/training/train:\r\n",
      "checkpoint\t\t\t\t     model.ckpt-1-00000-of-00001\r\n",
      "eval\t\t\t\t\t     model.ckpt-1.meta\r\n",
      "events.out.tfevents.1487209337.5fd6f503cb2d  model.ckpt-250-00000-of-00001\r\n",
      "graph.pbtxt\t\t\t\t     model.ckpt-250.meta\r\n"
     ]
    }
   ],
   "source": [
    "!ls {LOCAL_ROOT}/training/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"local_prediction\"></a>\n",
    "Local prediction\n",
    "================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local predict uses the model produced by training. The input data can be a csv string or Pandas DataFrame, but the schema must match the data set used for training. The target column is optional. As this was a classification problem, a probability is computed for each target label. As top_n=3 was used, the 3 labels associated with the 3 largest probabilities are returned by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting local prediction.\n",
      "Local prediction done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_from_input</th>\n",
       "      <th>target_from_input</th>\n",
       "      <th>top_1_label</th>\n",
       "      <th>top_1_score</th>\n",
       "      <th>top_2_label</th>\n",
       "      <th>top_2_score</th>\n",
       "      <th>top_3_label</th>\n",
       "      <th>top_3_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.735619e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>6.514290e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>7.004450e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.999864</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.569044e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>2.154754e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0.999855</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>6.613328e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key_from_input target_from_input      top_1_label  top_1_score  \\\n",
       "0           101.0    Iris-virginica   Iris-virginica     0.999946   \n",
       "1           107.0    Iris-virginica  Iris-versicolor     0.996429   \n",
       "2           100.0   Iris-versicolor  Iris-versicolor     0.999383   \n",
       "3            70.0   Iris-versicolor  Iris-versicolor     0.999864   \n",
       "4            13.0       Iris-setosa      Iris-setosa     0.999907   \n",
       "5            11.0       Iris-setosa      Iris-setosa     0.999855   \n",
       "\n",
       "       top_2_label  top_2_score     top_3_label  top_3_score\\n  \n",
       "0  Iris-versicolor     0.000054     Iris-setosa   1.735619e-11  \n",
       "1   Iris-virginica     0.003571     Iris-setosa   6.514290e-10  \n",
       "2   Iris-virginica     0.000616     Iris-setosa   7.004450e-07  \n",
       "3   Iris-virginica     0.000136     Iris-setosa   1.569044e-08  \n",
       "4  Iris-versicolor     0.000091  Iris-virginica   2.154754e-06  \n",
       "5  Iris-versicolor     0.000138  Iris-virginica   6.613328e-06  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.local_predict(\n",
    "  model_dir=os.path.join(LOCAL_ROOT, 'training/model'),\n",
    "  data=['Iris-virginica,101,6.3,3.3,6,2.5',\n",
    "        'Iris-virginica,107,4.9,2.5,4.5,1.7',\n",
    "        'Iris-versicolor,100,5.7,2.8,4.1,1.3',\n",
    "        'Iris-versicolor,70,5.6,2.5,3.9,1.1',\n",
    "        'Iris-setosa,13,4.8,3,1.4,0.1',\n",
    "        'Iris-setosa,11,5.4,3.7,1.5,0.2']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting local prediction.\n",
      "Local prediction done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_from_input</th>\n",
       "      <th>target_from_input</th>\n",
       "      <th>top_1_label</th>\n",
       "      <th>top_1_score</th>\n",
       "      <th>top_2_label</th>\n",
       "      <th>top_2_score</th>\n",
       "      <th>top_3_label</th>\n",
       "      <th>top_3_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.999946</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.735619e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>6.514278e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>7.004450e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   key_from_input target_from_input      top_1_label  top_1_score  \\\n",
       "0           101.0           UNKNOWN   Iris-virginica     0.999946   \n",
       "1           107.0           UNKNOWN  Iris-versicolor     0.996429   \n",
       "2           100.0           UNKNOWN  Iris-versicolor     0.999383   \n",
       "\n",
       "       top_2_label  top_2_score  top_3_label  top_3_score\\n  \n",
       "0  Iris-versicolor     0.000054  Iris-setosa   1.735619e-11  \n",
       "1   Iris-virginica     0.003571  Iris-setosa   6.514278e-10  \n",
       "2   Iris-virginica     0.000616  Iris-setosa   7.004450e-07  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sd.local_predict(\n",
    "  model_dir=os.path.join(LOCAL_ROOT, 'training/model'),\n",
    "  data=pd.DataFrame(\n",
    "    [[101,6.3,3.3,6,2.5],\n",
    "     [107,4.9,2.5,4.5,1.7],\n",
    "     [100,5.7,2.8,4.1,1.3]])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"local_batch_prediction\"></a>\n",
    "Local batch prediction\n",
    "============"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local batch prediction runs prediction on batched input data. This is ideal if the input dataset is very large or you have limited avaliable main memeory. However, for trully large datasets, it is better to run batch prediction using the cloudml services. Two output formats are supported, csv and json. The output may also be shardded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -fr {LOCAL_ROOT}/predict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting local batch prediction.\n",
      "Local batch prediction done.\n"
     ]
    }
   ],
   "source": [
    "sd.local_batch_predict(\n",
    "  model_dir=os.path.join(LOCAL_ROOT, 'training/model'),\n",
    "  prediction_input_file=os.path.join(LOCAL_ROOT, 'eval.*'),\n",
    "  output_dir=os.path.join(LOCAL_ROOT, 'predict_out'),\n",
    "  output_format='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_header.txt\terrors-00000-of-00001.txt  predictions-00000-of-00001.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls {LOCAL_ROOT}/predict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /content/Downloads/iris_notebook_workspace/predict_outt/csv_header.txt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat {LOCAL_ROOT}/predict_outt/csv_header.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat {LOCAL_ROOT}/predict_out/errors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.0,Iris-virginica,Iris-versicolor,0.996429145336,Iris-virginica,0.00357083650306,Iris-setosa,6.51429021836e-10\r\n",
      "100.0,Iris-versicolor,Iris-versicolor,0.999382972717,Iris-virginica,0.000616324367002,Iris-setosa,7.0044501399e-07\r\n",
      "99.0,Iris-versicolor,Iris-versicolor,0.997950255871,Iris-setosa,0.00104523065966,Iris-virginica,0.00100453919731\r\n",
      "13.0,Iris-setosa,Iris-setosa,0.999907016754,Iris-versicolor,9.08611036721e-05,Iris-virginica,2.15475415644e-06\r\n",
      "70.0,Iris-versicolor,Iris-versicolor,0.999863505363,Iris-virginica,0.000136479648063,Iris-setosa,1.56904427229e-08\r\n",
      "11.0,Iris-setosa,Iris-setosa,0.999855399132,Iris-versicolor,0.000137973052915,Iris-virginica,6.6133211476e-06\r\n",
      "37.0,Iris-setosa,Iris-setosa,0.99981969595,Iris-versicolor,0.000173512031324,Iris-virginica,6.75060709909e-06\r\n",
      "69.0,Iris-versicolor,Iris-versicolor,0.750553905964,Iris-virginica,0.249446064234,Iris-setosa,3.83428640401e-13\r\n",
      "40.0,Iris-setosa,Iris-setosa,0.999869585037,Iris-versicolor,0.0001257959957,Iris-virginica,4.59423063148e-06\r\n",
      "101.0,Iris-virginica,Iris-virginica,0.999945759773,Iris-versicolor,5.4256295698e-05,Iris-setosa,1.73561911371e-11\r\n"
     ]
    }
   ],
   "source": [
    "!head {LOCAL_ROOT}/predict_out/predictions-00000*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -fr {LOCAL_ROOT}/predict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting local batch prediction.\n",
      "Local batch prediction done.\n"
     ]
    }
   ],
   "source": [
    "sd.local_batch_predict(\n",
    "  model_dir=os.path.join(LOCAL_ROOT, 'training/model'),\n",
    "  prediction_input_file=os.path.join(LOCAL_ROOT, 'predict.*'),\n",
    "  output_dir=os.path.join(LOCAL_ROOT, 'predict_out'),\n",
    "  output_format='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "errors-00000-of-00001.txt  predictions-00000-of-00001.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls {LOCAL_ROOT}/predict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"top_2_label\": \"Iris-virginica\",\"top_3_score\": 6.514290218362362e-10,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.003570836503058672,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9964291453361511,\"key_from_input\": 107.0}\r\n",
      "{\"top_2_label\": \"Iris-virginica\",\"top_3_score\": 7.004450139902474e-07,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.0006163243670016527,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9993829727172852,\"key_from_input\": 100.0}\r\n",
      "{\"top_2_label\": \"Iris-setosa\",\"top_3_score\": 0.0010045391973108053,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.0010452306596562266,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9979502558708191,\"key_from_input\": 99.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 2.1547541564359562e-06,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 9.086110367206857e-05,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9999070167541504,\"key_from_input\": 13.0}\r\n",
      "{\"top_2_label\": \"Iris-virginica\",\"top_3_score\": 1.5690442722871012e-08,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.0001364796480629593,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9998635053634644,\"key_from_input\": 70.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 6.613321147597162e-06,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 0.0001379730529151857,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9998553991317749,\"key_from_input\": 11.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 6.750607099093031e-06,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 0.00017351203132420778,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9998196959495544,\"key_from_input\": 37.0}\r\n",
      "{\"top_2_label\": \"Iris-virginica\",\"top_3_score\": 3.834286404005849e-13,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.2494460642337799,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.7505539059638977,\"key_from_input\": 69.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 4.5942306314827874e-06,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 0.00012579599570017308,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9998695850372314,\"key_from_input\": 40.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 1.735619113707454e-11,\"top_1_label\": \"Iris-virginica\",\"top_2_score\": 5.425629569799639e-05,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9999457597732544,\"key_from_input\": 101.0}\r\n"
     ]
    }
   ],
   "source": [
    "!head {LOCAL_ROOT}/predict_out/predictions-00000*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cloud_preprocessing\"></a>\n",
    "Cloud preprocessing from csv files\n",
    "====\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets move our local fiels to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///content/Downloads/iris_notebook_workspace/eval.csv [Content-Type=text/csv]...\n",
      "Copying file:///content/Downloads/iris_notebook_workspace/predict.csv [Content-Type=text/csv]...\n",
      "Copying file:///content/Downloads/iris_notebook_workspace/train.csv [Content-Type=text/csv]...\n",
      "- [3 files][  5.3 KiB/  5.3 KiB]                                                \n",
      "Operation completed over 3 objects/5.3 KiB.                                      \n",
      "Copying file:///content/Downloads/iris_notebook_workspace/schema.json [Content-Type=application/json]...\n",
      "/ [1 files][  573.0 B/  573.0 B]                                                \n",
      "Operation completed over 1 objects/573.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {LOCAL_ROOT}/*.csv {CLOUD_ROOT}\n",
    "!gsutil cp {LOCAL_ROOT}/schema.json {CLOUD_ROOT}/schema.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/preprocess/numerical_analysis.json#1487199911166963...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/preprocess/schema.json#1487199915017000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/preprocess/vocab_flower.csv#1487199914320299...\n",
      "/ [3 objects]                                                                   \n",
      "Operation completed over 3 objects.                                              \n"
     ]
    }
   ],
   "source": [
    "!gsutil rm -r {CLOUD_ROOT}/preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cloud preprocessing.\n",
      "Track BigQuery status at\n",
      "https://bigquery.cloud.google.com/queries/cloud-ml-dev\n",
      "Running numerical analysis...done.\n",
      "Running categorical analysis...done.\n",
      "Cloud preprocessing done.\n"
     ]
    }
   ],
   "source": [
    "sd.cloud_preprocess(\n",
    "  input_file_pattern=os.path.join(CLOUD_ROOT, 'train.*'),\n",
    "  output_dir=os.path.join(CLOUD_ROOT, 'preprocess'),\n",
    "  schema_file=os.path.join(CLOUD_ROOT, 'schema.json'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev_bdt/iris_notebook_workspace/preprocess/numerical_analysis.json\r\n",
      "gs://cloud-ml-dev_bdt/iris_notebook_workspace/preprocess/schema.json\r\n",
      "gs://cloud-ml-dev_bdt/iris_notebook_workspace/preprocess/vocab_flower.csv\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {CLOUD_ROOT}/preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"sepal_width\": {\r\n",
      "    \"max\": 4.4000000000000004,\r\n",
      "    \"mean\": 3.050833333333332,\r\n",
      "    \"min\": 2.0\r\n",
      "  },\r\n",
      "  \"petal_width\": {\r\n",
      "    \"max\": 2.5,\r\n",
      "    \"mean\": 1.2324999999999995,\r\n",
      "    \"min\": 0.10000000000000001\r\n",
      "  },\r\n",
      "  \"sepal_length\": {\r\n",
      "    \"max\": 7.9000000000000004,\r\n",
      "    \"mean\": 5.8675000000000024,\r\n",
      "    \"min\": 4.2999999999999998\r\n",
      "  },\r\n",
      "  \"key\": {\r\n",
      "    \"max\": 150.0,\r\n",
      "    \"mean\": 76.733333333333334,\r\n",
      "    \"min\": 1.0\r\n",
      "  },\r\n",
      "  \"petal_length\": {\r\n",
      "    \"max\": 6.9000000000000004,\r\n",
      "    \"mean\": 3.8308333333333349,\r\n",
      "    \"min\": 1.1000000000000001\r\n",
      "  }\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!gsutil cat {CLOUD_ROOT}/preprocess/numerical_analysis.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa\r\n",
      "Iris-versicolor\r\n",
      "Iris-virginica\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat {CLOUD_ROOT}/preprocess/vocab_flower.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cloud_training\"></a>\n",
    "Cloud Training\n",
    "==========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cloud training, all input files must be placed on GCS. The functino cloud_train builds the trainer, uploads it to GCS, and submits a job request to the CloudML service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file:///content/Downloads/iris_notebook_workspace/transforms.json [Content-Type=application/json]...\n",
      "/ [1 files][  226.0 B/  226.0 B]                                                \n",
      "Operation completed over 1 objects/226.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {LOCAL_ROOT}/transforms.json {CLOUD_ROOT}/transforms.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/intermediate_models/#1487203863800309...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/intermediate_models/00000000/#1487203867746000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/intermediate_models/00000000/checkpoint#1487203868102000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/intermediate_models/00000000/export#1487203868571000...\n",
      "/ [4 objects]                                                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m -o ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/intermediate_models/00000000/export.meta#1487203869134000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/model/#1487203873068000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/model/checkpoint#1487203871364000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/model/export#1487203872088000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/model/export.meta#1487203872755397...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/model/schema.json#1487203874838282...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/model/transforms.json#1487203873625320...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/model/vocab_flower.csv#1487203875440000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/staging/sd.tar.gz#1487203590403400...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/train/#1487203852625000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/train/checkpoint#1487203858915879...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/train/events.out.tfevents.1487203852.master-aedab268fc-0-b3b95#1487203856972000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/train/graph.pbtxt#1487203855794000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/train/model.ckpt-0-00000-of-00001#1487203857659000...\n",
      "Removing gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/train/model.ckpt-0.meta#1487203860254000...\n",
      "/ [19 objects]                                                                  \n",
      "Operation completed over 19 objects.                                             \n"
     ]
    }
   ],
   "source": [
    "!gsutil rm -r {CLOUD_ROOT}/training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/staging/sd.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Job Request Sent:<br /><pre>{\n",
       "  \"package_uris\": [\n",
       "    \"gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/staging/sd.tar.gz\"\n",
       "  ],\n",
       "  \"args\": [\n",
       "    \"--train_data_paths=gs://cloud-ml-dev_bdt/iris_notebook_workspace/train.cs*\",\n",
       "    \"--eval_data_paths=gs://cloud-ml-dev_bdt/iris_notebook_workspace/eval.cs*\",\n",
       "    \"--output_path=gs://cloud-ml-dev_bdt/iris_notebook_workspace/training\",\n",
       "    \"--preprocess_output_dir=gs://cloud-ml-dev_bdt/iris_notebook_workspace/preprocess\",\n",
       "    \"--transforms_file=gs://cloud-ml-dev_bdt/iris_notebook_workspace/transforms.json\",\n",
       "    \"--model_type=dnn_classification\",\n",
       "    \"--max_steps=500\",\n",
       "    \"--layer_size1=10\",\n",
       "    \"--layer_size2=10\",\n",
       "    \"--layer_size3=5\",\n",
       "    \"--top_n=3\"\n",
       "  ],\n",
       "  \"python_module\": \"datalab_solutions.structured_data.trainer.task\",\n",
       "  \"region\": \"us-central1\",\n",
       "  \"scale_tier\": \"BASIC\"\n",
       "}</pre><p>Click <a href=\"https://console.developers.google.com/ml/jobs?project=cloud-ml-dev\" target=\"_blank\">here</a> to track the training job structured_data_train_170216_011330.</p><br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sd.cloud_train(\n",
    "  train_file_pattern=os.path.join(CLOUD_ROOT, 'train.cs*'),\n",
    "  eval_file_pattern=os.path.join(CLOUD_ROOT, 'eval.cs*'),\n",
    "  preprocess_output_dir=os.path.join(CLOUD_ROOT, 'preprocess'),\n",
    "  output_dir=os.path.join(CLOUD_ROOT, 'training'),\n",
    "  transforms_file=os.path.join(CLOUD_ROOT, 'transforms.json'),\n",
    "  model_type='dnn_classification',\n",
    "  top_n=3,\n",
    "  max_steps=500,\n",
    "  layer_sizes=[10, 10, 5],\n",
    "  region='us-central1',\n",
    "  scale_tier='BASIC'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the next steps, follow the above link and wait ~10 minutes for training to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: One or more URLs matched no objects.\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {CLOUD_ROOT}/training/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cloud_online_prediction\"></a>\n",
    "CloudML online prediction\n",
    "========================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training a model, it can be depolyed and requests can be sent to it. We first have to create the model, and its version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'irismodeldatalab'\n",
    "MODEL_VERSION = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m `--regions` flag will soon be required. Please explicitly specify a region. Using [us-central1] by default.\n",
      "Creating version (this might take a few minutes)......done.\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ml models create {MODEL_NAME} \n",
    "!gcloud beta ml versions create {MODEL_VERSION} --model {MODEL_NAME} --origin {CLOUD_ROOT}/training/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_from_input</th>\n",
       "      <th>target_from_input</th>\n",
       "      <th>top_1_label</th>\n",
       "      <th>top_1_score</th>\n",
       "      <th>top_2_label</th>\n",
       "      <th>top_2_score</th>\n",
       "      <th>top_3_label</th>\n",
       "      <th>top_3_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>2.61211e-09</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>4.48302e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>107</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>4.24274e-09</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>4.41757e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>8.67259e-06</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>5.83575e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.1382e-06</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>1.26933e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0.999835</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>0.000164935</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>0.999937</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>6.28423e-05</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key_from_input target_from_input      top_1_label top_1_score  \\\n",
       "0            101    Iris-virginica   Iris-virginica           1   \n",
       "1            107    Iris-virginica  Iris-versicolor           1   \n",
       "2            100   Iris-versicolor  Iris-versicolor    0.999991   \n",
       "3             70   Iris-versicolor  Iris-versicolor    0.999999   \n",
       "4             13       Iris-setosa      Iris-setosa    0.999835   \n",
       "5             11       Iris-setosa      Iris-setosa    0.999937   \n",
       "\n",
       "       top_2_label  top_2_score     top_3_label  top_3_score  \n",
       "0  Iris-versicolor  2.61211e-09     Iris-setosa  4.48302e-23  \n",
       "1      Iris-setosa  4.24274e-09  Iris-virginica  4.41757e-10  \n",
       "2      Iris-setosa  8.67259e-06  Iris-virginica  5.83575e-14  \n",
       "3      Iris-setosa   1.1382e-06  Iris-virginica  1.26933e-17  \n",
       "4  Iris-versicolor  0.000164935  Iris-virginica            0  \n",
       "5  Iris-versicolor  6.28423e-05  Iris-virginica            0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.cloud_predict(\n",
    "  model_name=MODEL_NAME,\n",
    "  model_version=MODEL_VERSION,\n",
    "  data=['Iris-virginica,101,6.3,3.3,6,2.5',\n",
    "        'Iris-virginica,107,4.9,2.5,4.5,1.7',\n",
    "        'Iris-versicolor,100,5.7,2.8,4.1,1.3',\n",
    "        'Iris-versicolor,70,5.6,2.5,3.9,1.1',\n",
    "        'Iris-setosa,13,4.8,3,1.4,0.1',\n",
    "        'Iris-setosa,11,5.4,3.7,1.5,0.2']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"cloud_batch_prediction\"></a>\n",
    "CloudML Batch prediction\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: \"rm\" command does not support \"file://\" URLs. Did you mean to use a gs:// URL?\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil rm -fr {CLOUD_ROOT}/predict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://cloud-ml-dev_bdt/iris_notebook_workspace/predict_out/staging/sd.tar.gz\n",
      "['predict.py', '--cloud', '--project_id=cloud-ml-dev', '--predict_data=gs://cloud-ml-dev_bdt/iris_notebook_workspace/predict.cs*', '--trained_model_dir=gs://cloud-ml-dev_bdt/iris_notebook_workspace/training/model', '--output_dir=gs://cloud-ml-dev_bdt/iris_notebook_workspace/predict_out', '--output_format=json', '--batch_size=1000', '--extra_package=gs://cloud-ml-dev_bdt/iris_notebook_workspace/predict_out/staging/sd.tar.gz']\n",
      "Starting cloud batch prediction.\n",
      "Dataflow Job submitted, see Job structured-data-batch-prediction-20170216013432 at https://console.developers.google.com/dataflow?project=cloud-ml-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/apache_beam/coders/typecoders.py:136: UserWarning:\n",
      "\n",
      "Using fallback coder for typehint: Any.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See above link for job status.\n"
     ]
    }
   ],
   "source": [
    "sd.cloud_batch_predict(\n",
    "  model_dir=os.path.join(CLOUD_ROOT, 'training/model'),\n",
    "  prediction_input_file=os.path.join(CLOUD_ROOT, 'predict.cs*'),\n",
    "  output_dir=os.path.join(CLOUD_ROOT, 'predict_out'),\n",
    "  output_format='json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev_bdt/iris_notebook_workspace/predict_out/errors-00000-of-00001.txt\r\n",
      "gs://cloud-ml-dev_bdt/iris_notebook_workspace/predict_out/predictions-00000-of-00003.json\r\n",
      "gs://cloud-ml-dev_bdt/iris_notebook_workspace/predict_out/predictions-00001-of-00003.json\r\n",
      "gs://cloud-ml-dev_bdt/iris_notebook_workspace/predict_out/predictions-00002-of-00003.json\r\n",
      "gs://cloud-ml-dev_bdt/iris_notebook_workspace/predict_out/staging/\r\n",
      "gs://cloud-ml-dev_bdt/iris_notebook_workspace/predict_out/tmp/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {CLOUD_ROOT}/predict_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"top_2_label\": \"Iris-virginica\",\"top_3_score\": 3.611174692608188e-09,\"top_1_label\": \"Iris-versicolor\",\"top_2_score\": 0.008518863469362259,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9914811849594116,\"key_from_input\": 55.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 0.0,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 5.8058707509189844e-05,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9999419450759888,\"key_from_input\": 49.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 4.999267059352386e-13,\"top_1_label\": \"Iris-virginica\",\"top_2_score\": 0.002931889146566391,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9970681071281433,\"key_from_input\": 78.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 3.8751211441090394e-12,\"top_1_label\": \"Iris-virginica\",\"top_2_score\": 0.25968462228775024,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.7403153777122498,\"key_from_input\": 73.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 4.784760878832051e-25,\"top_1_label\": \"Iris-virginica\",\"top_2_score\": 9.799880906768976e-10,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 1.0,\"key_from_input\": 136.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 0.0,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 1.6028314348659478e-05,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9999840259552002,\"key_from_input\": 33.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 6.710444299705675e-19,\"top_1_label\": \"Iris-virginica\",\"top_2_score\": 2.3175782359885488e-07,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9999997615814209,\"key_from_input\": 125.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 6.911594370830401e-14,\"top_1_label\": \"Iris-virginica\",\"top_2_score\": 0.004085878375917673,\"top_3_label\": \"Iris-setosa\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9959141612052917,\"key_from_input\": 143.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 0.0,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 0.0001589785679243505,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9998409748077393,\"key_from_input\": 21.0}\r\n",
      "{\"top_2_label\": \"Iris-versicolor\",\"top_3_score\": 0.0,\"top_1_label\": \"Iris-setosa\",\"top_2_score\": 5.217856960371137e-05,\"top_3_label\": \"Iris-virginica\",\"target_from_input\": \"UNKNOWN\",\"top_1_score\": 0.9999477863311768,\"key_from_input\": 5.0}\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat {CLOUD_ROOT}/predict_out/predictions-00000-*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
