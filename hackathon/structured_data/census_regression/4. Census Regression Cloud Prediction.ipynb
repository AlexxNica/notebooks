{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"about\"></a>\n",
    "About this notebook\n",
    "======\n",
    "\n",
    "This notebook assumes you have ran the local Census Regression notebook and you have not deleted the LOCAL_ROOT folder. In this notebook, we will use online and batch prediction on a pre-trained Tensorflow model on CloudML. This notebook will does not assume that the notebook \"3. Census Regression Cloud Training\" was executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"setup\"></a>\n",
    "Setting things up\n",
    "====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datalab_solutions.structured_data as sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the versions of structured_data and TF we have. Make sure TF is 1.0.0, and SD is 0.0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf 1.0.0\n",
      "sd 0.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.lib.io import file_io\n",
    "\n",
    "import datalab.mlalpha as mlalpha\n",
    "\n",
    "print('tf ' + str(tf.__version__))\n",
    "print('sd ' + str(sd.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will write files during preprocessing, training, and prediction. Please give a root folder you wish to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://cloud-ml-dev-census-regression-datalab/...\n",
      "ServiceException: 409 Bucket cloud-ml-dev-census-regression-datalab already exists.\n"
     ]
    }
   ],
   "source": [
    "LOCAL_ROOT = './census_regression_workspace' # This should be the same as what was used in the local census notebook\n",
    "CLOUD_ROOT = 'gs://' + datalab_project_id() + '-census-regression-datalab'\n",
    "\n",
    "if not file_io.file_exists(LOCAL_ROOT):\n",
    "  raise ValueErro('LOCAL_ROOT not found. Did you run the local notebook?')\n",
    "!gsutil mb {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us put the csv files on GCS and the output of preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./census_regression_workspace/predict_data.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/eval_data.csv [Content-Type=text/csv]...\n",
      "Copying file://./census_regression_workspace/train_data.csv [Content-Type=text/csv]...\n",
      "/ [3/3 files][200.1 KiB/200.1 KiB] 100% Done                                    \n",
      "Operation completed over 3 objects/200.1 KiB.                                    \n",
      "Copying file://./census_regression_workspace/training/model/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/model/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/model/assets.extra/transforms.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/model/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/model/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-2000.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-2000.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/graph.pbtxt [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/events.out.tfevents.1487805787.8786f0ef654e [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-1.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/evaluation_model/assets.extra/transforms.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-1.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/eval/events.out.tfevents.1487805811.8786f0ef654e [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/checkpoint [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-1.meta [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/model.ckpt-2000.meta [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1487805813820/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1487805813820/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1487805817270/assets.extra/transforms.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1487805817270/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1487805817270/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1487805817270/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_prediction_models/1487805817270/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1487805813820/assets.extra/schema.json [Content-Type=application/json]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1487805813820/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://./census_regression_workspace/training/train/export/intermediate_evaluation_models/1487805813820/assets.extra/transforms.json [Content-Type=application/json]...\n",
      "|\n",
      "Operation completed over 30 objects/9.5 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp {os.path.join(LOCAL_ROOT, '*_data.csv')} {CLOUD_ROOT}\n",
    "!gsutil -m cp -r {os.path.join(LOCAL_ROOT, 'training')} {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-census-regression-datalab/training/evaluation_model/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/training/model/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/training/staging/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/training/train/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {CLOUD_ROOT}/training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"local_preprocessing\"></a>\n",
    "Cloudml Batch Prediction\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch prediction has two modes. In the 'evaluation' mode, the input data is expected to 100% match the training schema, meaning the target column should exist in the data. In 'prediction' mode, the input data files must match the training schema except that the target column is missing. Note that cloudml batch prediction can be slow on small datasets because it takes a while for a Dataflow job to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -r {CLOUD_ROOT}/batch_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building package and uploading to gs://cloud-ml-dev-census-regression-datalab/batch_prediction/staging/sd.tar.gz\n",
      "Starting cloud batch prediction.\n",
      "Dataflow Job submitted, see Job structured-data-batch-prediction-20170223013027 at https://console.developers.google.com/dataflow?project=cloud-ml-dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/apache_beam/coders/typecoders.py:136: UserWarning:\n",
      "\n",
      "Using fallback coder for typehint: Any.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See above link for job status.\n"
     ]
    }
   ],
   "source": [
    "sd.cloud_batch_predict(\n",
    "  training_ouput_dir=os.path.join(CLOUD_ROOT, 'training'),\n",
    "  prediction_input_file=os.path.join(CLOUD_ROOT, 'eval_data.*'),\n",
    "  output_dir=os.path.join(CLOUD_ROOT, 'batch_prediction'),\n",
    "  mode='evaluation',\n",
    "  output_format='json'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training is done, {CLOUD_ROOT}/training should contain the folders train, model, evaluation_model, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/errors-00000-of-00001.txt\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/predictions-00000-of-00003.json\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/predictions-00001-of-00003.json\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/predictions-00002-of-00003.json\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/staging/\r\n",
      "gs://cloud-ml-dev-census-regression-datalab/batch_prediction/tmp/\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls  {CLOUD_ROOT}/batch_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cloudml Online Prediction\n",
    "=========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to deploy an app engine model, and then we can make requests on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m `--regions` flag will soon be required. Please explicitly specify a region. Using [us-central1] by default.\n",
      "Creating version (this might take a few minutes)......done.\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ml models create census_model\n",
    "!gcloud beta ml versions create v1 --model census_model --origin {CLOUD_ROOT}/training/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_from_input</th>\n",
       "      <th>predicted_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>32.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1225</td>\n",
       "      <td>52.2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226</td>\n",
       "      <td>23.2904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key_from_input predicted_target\n",
       "0            490          32.4215\n",
       "1           1225          52.2748\n",
       "2           1226          23.2904"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.cloud_predict(\n",
    "  model_name='census_model',\n",
    "  model_version='v1',\n",
    "  data=['490,64,2,0,1,0,2,8090,015,01,1,00590,00500,1,18,0,2,1',\n",
    "        '1225,32,5,0,4,5301,2,9680,015,01,1,00100,00100,1,21,2,1,1',\n",
    "        '1226,30,1,0,1,0,2,8680,020,01,1,00100,00100,1,16,0,2,1']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_from_input</th>\n",
       "      <th>predicted_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>490</td>\n",
       "      <td>32.4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1225</td>\n",
       "      <td>52.2748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226</td>\n",
       "      <td>23.2904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  key_from_input predicted_target\n",
       "0            490          32.4215\n",
       "1           1225          52.2748\n",
       "2           1226          23.2904"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd.cloud_predict(\n",
    "  model_name='census_model',\n",
    "  model_version='v1',\n",
    "  data=pd.DataFrame(\n",
    "    [[490,64,2,0,1,0,2,8090,\"015\",\"01\",1,\"00590\",\"00500\",1,18,0,2,1],\n",
    "     [1225,32,5,0,4,5301,2,9680,\"015\",\"01\",1,\"00100\",\"00100\",1,21,2,1,1],\n",
    "     [1226,30,1,0,1,0,2,8680,\"020\",\"01\",1,\"00100\",\"00100\",1,16,0,2,1]])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning things up\n",
    "====="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to delete the files you made on GCS, uncomment and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!gsutil rm -fr {CLOUD_ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete the models created, uncomment and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting version [v1]......done.\n",
      "Deleting model [census_model]...done.\n"
     ]
    }
   ],
   "source": [
    "#!gcloud beta ml versions delete v1 --model census_model \n",
    "#!gcloud beta ml models delete census_model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
