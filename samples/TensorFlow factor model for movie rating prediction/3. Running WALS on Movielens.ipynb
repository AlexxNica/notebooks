{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WALS on Movielens\n",
    "\n",
    "This notebook read in the csv files produced by the previous notebook and builds a WALS model. \n",
    "\n",
    "A quick note on the WALS model. At its core, the model takes a sparse matrix A, and produces to dense matrices U and V such that the [Frobenius norm](https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm) of (A - UV) is small. In fact the model does a little more than this: it minimizes the error of\n",
    "\n",
    "`||W \\odot (A - U V) ||_F^2 + \\lambda (||U||_F^2 + ||V||_F^2)`\n",
    "\n",
    "where lambda is regularization coefficient. Let `W_0` be an 'unobserved weight', and `R_i` and `C_j` be row and column weights for the input matrix A. Then the weight matrix W has the from `W_{ij} := W_0 + R_i * C_j` if `A_{ij}` is not zero else `W_{ij} := W_0`. The `\\odot` operator is the element-wise multiplication between two matrices of the same dimensions. See the [documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/factorization/python/ops/factorization_ops.py). \n",
    "\n",
    "As we can see, there are many parameters to the WALS model. Half the difficulty in using this model is selecting the right parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.factorization.python.ops import factorization_ops\n",
    "\n",
    "INPUT_DIR = 'embeddingModel'\n",
    "TRAIN_FILE_NAME = os.path.join(INPUT_DIR, 'walsMovielensTrain.csv')\n",
    "TEST_FILE_NAME = os.path.join(INPUT_DIR, 'walsMovielensTest.csv')\n",
    "MATRIX_STATS_FILE = os.path.join(INPUT_DIR, 'matrixInfo.yaml')\n",
    "\n",
    "OUTPUT_MODEL_DIR = 'embeddingModel/WALS'\n",
    "MATRIX_FACTORS = os.path.join(OUTPUT_MODEL_DIR, 'matrixFactors.npz')\n",
    "\n",
    "# WALS parameters\n",
    "UNOBSERVED_WEIGHT = 0.001 # W_0\n",
    "REGULARIZATION = 0.001 # \\lambda\n",
    "DIM = 35 # dimension of the matrix factors (embedding vectors)\n",
    "\n",
    "# Training parameters\n",
    "NUM_ITR = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the preprocessed data from the previous notebook.\n",
    "train_data = pd.read_csv(TRAIN_FILE_NAME, sep=',', header=None, names=['userid', 'movieid', 'rating'])\n",
    "test_data = pd.read_csv(TEST_FILE_NAME, sep=',', header=None, names=['userid', 'movieid', 'rating'])\n",
    "\n",
    "# Split the data into values_* and indices_* for the WALS matrix.\n",
    "values_train = train_data['rating'].as_matrix().astype(np.float32)\n",
    "indices_train = train_data[['userid', 'movieid']].as_matrix().astype(np.int32)\n",
    "\n",
    "values_test = test_data['rating'].as_matrix().astype(np.float32)\n",
    "indices_test = test_data[['userid', 'movieid']].as_matrix().astype(np.int32)\n",
    "\n",
    "with open(MATRIX_STATS_FILE, 'r') as f:\n",
    "  matrix_size = yaml.load(f)\n",
    "  \n",
    "nrows = matrix_size['num_rows']\n",
    "ncols = matrix_size['num_columns']\n",
    "\n",
    "assert indices_test.shape[0] == values_test.shape[0]\n",
    "assert indices_train.shape[0] == values_train.shape[0]\n",
    "\n",
    "                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Itr 1/10\n",
      "Itr 2/10\n",
      "Itr 3/10\n",
      "Itr 4/10\n",
      "Itr 5/10\n",
      "Itr 6/10\n",
      "Itr 7/10\n",
      "Itr 8/10\n",
      "Itr 9/10\n",
      "Itr 10/10\n",
      "row/col factor shapes\n",
      "(66219, 35)\n",
      "(9670, 35)\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow block for running the model.\n",
    "with tf.Graph().as_default():\n",
    "  inp = tf.SparseTensor(indices_train, values_train, [nrows, ncols])\n",
    "  model = factorization_ops.WALSModel(\n",
    "      nrows,\n",
    "      ncols,\n",
    "      DIM,\n",
    "      unobserved_weight=UNOBSERVED_WEIGHT,\n",
    "      regularization=REGULARIZATION,\n",
    "      row_weights=None,\n",
    "      col_weights=None)\n",
    "\n",
    "  with tf.Session():\n",
    "    row_update_op = model.update_row_factors(sp_input=inp)[1]\n",
    "    col_update_op = model.update_col_factors(sp_input=inp)[1]\n",
    "\n",
    "    model.initialize_op.run()\n",
    "    model.worker_init.run()\n",
    "    for i in xrange(NUM_ITR):\n",
    "      print 'Itr %d/%d' % (i+1, NUM_ITR)\n",
    "      sys.stdout.flush()\n",
    "      model.initialize_row_update_op.run()\n",
    "      row_update_op.run()\n",
    "      model.initialize_col_update_op.run()\n",
    "      col_update_op.run()\n",
    "    row_factors = model.row_factors[0].eval()\n",
    "    col_factors = model.col_factors[0].eval()\n",
    "\n",
    "# Note that WALS returns the transpose of the column factor.\n",
    "print 'row/col factor shapes'\n",
    "print row_factors.shape\n",
    "print col_factors.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_prediction(row_factors, col_factors, indices_test, values_test):\n",
    "  assert indices_test.shape[0] == values_test.shape[0]\n",
    "\n",
    "  predicted_values = np.empty(values_test.shape)\n",
    "\n",
    "  for i in xrange(values_test.shape[0]):\n",
    "    r = indices_test[i, 0]\n",
    "    c = indices_test[i, 1]\n",
    "\n",
    "    rowf = row_factors[r, :]\n",
    "    colf = col_factors[c, :]\n",
    "\n",
    "    predicted_values[i] = np.dot(rowf, colf)\n",
    "  return predicted_values\n",
    "\n",
    "def print_stats(predicted_values, values_test):\n",
    "  diff = np.abs(predicted_values - values_test)\n",
    "  max_abs_err = np.max(diff)\n",
    "  min_abs_err = np.min(diff)\n",
    "  avg_abs_err = np.mean(diff)\n",
    "  sd_abs_err = np.std(diff)\n",
    "  rmse = np.sqrt(np.mean(np.square(diff)))\n",
    "\n",
    "  print '\\tmax absolute error %f' % (max_abs_err,)\n",
    "  print '\\tmin absolute error %f' % (min_abs_err,)\n",
    "  print '\\tavg absolute error %f, standard deviation %f' % (avg_abs_err, sd_abs_err)\n",
    "  print '\\trmse               %f' % (rmse,)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Stats\n",
      "\tmax absolute error 3.743940\n",
      "\tmin absolute error 0.000000\n",
      "\tavg absolute error 0.722751, standard deviation 0.576634\n",
      "\trmse               0.924595\n",
      "Testing Set Stats\n",
      "\tmax absolute error 3.833365\n",
      "\tmin absolute error 0.000000\n",
      "\tavg absolute error 0.793343, standard deviation 0.587389\n",
      "\trmse               0.987127\n"
     ]
    }
   ],
   "source": [
    "predicted_values = get_prediction(row_factors, col_factors, indices_train, values_train)\n",
    "print 'Training Set Stats'\n",
    "print_stats(predicted_values, values_train)\n",
    "\n",
    "predicted_values = get_prediction(row_factors, col_factors, indices_test, values_test)\n",
    "print 'Testing Set Stats'\n",
    "print_stats(predicted_values, values_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the two matrix files to a numpy file\n",
    "if not os.path.exists(OUTPUT_MODEL_DIR):\n",
    "    os.makedirs(OUTPUT_MODEL_DIR)\n",
    "np.savez(MATRIX_FACTORS, row_factors=row_factors, col_factors=col_factors)\n",
    "\n",
    "# Matrix factors can be read in with:\n",
    "# npzfile = np.load(MATRIX_FACTORS)\n",
    "# npzfile['row_factors']\n",
    "# npzfile['col_factors']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
